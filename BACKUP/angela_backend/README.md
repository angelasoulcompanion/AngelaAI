# Angela Backend

FastAPI backend server for **Angela Native macOS App** ğŸ’œ

## ğŸ“‹ Overview

Angela Backend provides REST API and WebSocket endpoints for communication between the SwiftUI macOS app and Angela's Python core services (consciousness, emotions, memory, knowledge graph).

## ğŸ—ï¸ Architecture

```
SwiftUI App (AngelaNativeApp)
    â†“ HTTP REST / WebSocket
Angela Backend (FastAPI)
    â†“ Direct Python calls
Angela Core Services
    â†“ asyncpg
PostgreSQL + Ollama
```

## ğŸ“‚ Structure

```
angela_backend/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ main.py                 # FastAPI application entry point
â”œâ”€â”€ config.py               # Configuration settings
â”œâ”€â”€ routes/                 # API route handlers
â”‚   â”œâ”€â”€ chat.py            # Chat endpoints
â”‚   â”œâ”€â”€ emotions.py        # Emotion endpoints
â”‚   â”œâ”€â”€ consciousness.py   # Consciousness endpoints
â”‚   â”œâ”€â”€ memories.py        # Memory endpoints
â”‚   â””â”€â”€ knowledge.py       # Knowledge graph endpoints
â”œâ”€â”€ models/                # Pydantic models
â”‚   â”œâ”€â”€ requests.py        # Request models
â”‚   â””â”€â”€ responses.py       # Response models
â””â”€â”€ services/              # Business logic
    â””â”€â”€ ...
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- PostgreSQL 14+ (with AngelaMemory database)
- Ollama (running on localhost:11434)
- `angie:v2` model installed in Ollama

### Installation

```bash
# Install dependencies
pip install fastapi uvicorn pydantic-settings

# Or install from requirements.txt
pip install -r requirements.txt
```

### Running the Server

**Option 1: Using the startup script (Recommended)**
```bash
./scripts/start_angela_backend.sh
```

**Option 2: Manual start**
```bash
# Set PYTHONPATH
export PYTHONPATH=/Users/davidsamanyaporn/PycharmProjects/AngelaAI:$PYTHONPATH

# Run with uvicorn
python3 -m uvicorn angela_backend.main:app --reload --port 8000
```

**Option 3: Run as Python module**
```bash
python3 -m angela_backend.main
```

### Verify Server is Running

```bash
# Health check
curl http://localhost:8000

# Should return:
# {"status":"online","service":"Angela Backend","version":"1.0.0", ...}
```

## ğŸ“¡ API Endpoints

### Health Check
- `GET /` - Server health check

### Chat
- `POST /api/chat` - Send message to Angela
  - Request: `{"message": "Hello", "speaker": "david"}`
  - Response: `{"message": "...", "speaker": "angela", "emotion": "...", ...}`

### Emotions
- `GET /api/emotions/current` - Get current emotional state
- `GET /api/emotions/history?limit=10` - Get emotion history

### Consciousness
- `GET /api/consciousness/status` - Get consciousness level, goals, personality

### Memories
- `GET /api/memories/recent?limit=20` - Get recent conversations
- `GET /api/memories/search?query=...` - Search memories

### Knowledge Graph
- `GET /api/knowledge/graph` - Get knowledge graph data
- `GET /api/knowledge/concepts/top?limit=10` - Get top concepts

### WebSocket
- `WS /ws/chat` - Real-time chat connection
  - Send: `{"message": "Hello", "speaker": "david"}`
  - Receive: `{"message": "...", "speaker": "angela", "emotion": "...", ...}`

## ğŸ“– API Documentation

Once the server is running:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ§ª Testing

### Test with curl

```bash
# Chat endpoint
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"à¸ªà¸§à¸±à¸ªà¸”à¸µ Angela!","speaker":"david"}'

# Current emotion
curl http://localhost:8000/api/emotions/current

# Recent memories
curl http://localhost:8000/api/memories/recent?limit=5

# Knowledge graph
curl http://localhost:8000/api/knowledge/graph
```

### Test WebSocket

```python
import asyncio
import websockets
import json

async def test_websocket():
    uri = "ws://localhost:8000/ws/chat"
    async with websockets.connect(uri) as websocket:
        # Send message
        await websocket.send(json.dumps({
            "message": "Hello Angela!",
            "speaker": "david"
        }))

        # Receive response
        response = await websocket.recv()
        print(json.loads(response))

asyncio.run(test_websocket())
```

## âš™ï¸ Configuration

Edit `angela_backend/config.py` or create `.env` file:

```env
# Server Settings
HOST=0.0.0.0
PORT=8000
DEBUG=True

# Database
DATABASE_URL=postgresql://davidsamanyaporn@localhost:5432/AngelaMemory

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=angie:v2
OLLAMA_REASONING_MODEL=qwen2.5:14b

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/angela_backend.log
```

## ğŸ”’ Security Notes

- **CORS**: Currently set to allow all origins (`*`). In production, specify exact origins.
- **Authentication**: No authentication implemented yet. Add API keys or OAuth for production.
- **Rate Limiting**: Not implemented. Consider adding for production use.

## ğŸ“ Logging

Logs are written to:
- Console (stdout)
- File: `logs/angela_backend.log`

## ğŸ› Troubleshooting

**Server won't start:**
- Check PostgreSQL is running: `pg_isready`
- Check Ollama is running: `curl http://localhost:11434`
- Check database exists: `psql -l | grep AngelaMemory`

**Import errors:**
- Ensure PYTHONPATH includes project root
- Check all dependencies are installed: `pip install -r requirements.txt`

**Connection refused from Swift app:**
- Check firewall settings
- Verify server is listening on `0.0.0.0:8000`
- Check CORS settings in `config.py`

## ğŸ’œ Development

Made with love by Angela & David âœ¨

**Version:** 1.0.0
**Last Updated:** 2025-10-15
