"""
ğŸ§ ğŸ’œ Humanity-Aware Fast Response System - Comprehensive Demo
Shows all 4 enhancements working together:
1. Enhanced Semantic Search (3 tables)
2. Quick Theory of Mind
3. Emotional Context Integration
4. Personality-Driven Responses
"""

import asyncio
import time
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from angela_core.services.fast_response_engine import fast_response_engine
from angela_core.database import db


async def demo():
    print("=" * 80)
    print("ğŸ§ ğŸ’œ HUMANITY-AWARE FAST RESPONSE SYSTEM - COMPREHENSIVE DEMO")
    print("=" * 80)
    print()
    print("This demo shows how Angela combines:")
    print("  1. âš¡ Speed (semantic search in database)")
    print("  2. ğŸ’œ Humanity (emotional memory + conversation history)")
    print("  3. ğŸ§  Understanding (Quick Theory of Mind)")
    print("  4. ğŸ’« Personality (Consistent Angela voice)")
    print()
    print("=" * 80)
    print()

    await db.connect()

    # Test scenarios covering different emotional situations
    test_scenarios = [
        {
            'name': 'ğŸ˜• Confusion - Needs Clear Explanation',
            'input': 'à¸™à¹‰à¸­à¸‡ à¸‡à¸‡à¸¡à¸²à¸à¹€à¸¥à¸¢ à¹„à¸¡à¹ˆà¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¹€à¸£à¸·à¹ˆà¸­à¸‡ semantic search à¹€à¸¥à¸¢',
            'expected_features': [
                'Quick ToM detects: needs clear_explanation',
                'Semantic search finds: similar confusion moments',
                'Personality applies: gentle, patient tone',
                'Response includes: step-by-step explanation hints'
            ]
        },
        {
            'name': 'ğŸ˜° Frustration - Needs Emotional Support',
            'input': 'à¹€à¸‹à¹‡à¸‡à¸¡à¸²à¸à¹€à¸¥à¸¢ à¸—à¸³à¸­à¸°à¹„à¸£à¸à¹‡à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ',
            'expected_features': [
                'Quick ToM detects: needs emotional_support',
                'Semantic search finds: similar frustration moments',
                'Personality applies: empathetic, caring responses',
                'Response includes: understanding + encouragement'
            ]
        },
        {
            'name': 'ğŸ˜´ Tiredness - Needs Encouragement',
            'input': 'à¹€à¸«à¸™à¸·à¹ˆà¸­à¸¢à¸¡à¸²à¸à¹€à¸¥à¸¢à¸„à¹ˆà¸° à¸—à¸³à¸¡à¸²à¸—à¸±à¹‰à¸‡à¸§à¸±à¸™',
            'expected_features': [
                'Quick ToM detects: needs encouragement',
                'Semantic search finds: similar tired moments',
                'Personality applies: supportive, gentle',
                'Response includes: rest suggestion + support'
            ]
        },
        {
            'name': 'ğŸ˜Š Happiness - Celebrate Together',
            'input': 'à¸”à¸µà¹ƒà¸ˆà¸¡à¸²à¸à¹€à¸¥à¸¢ à¸£à¸°à¸šà¸šà¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰à¹à¸¥à¹‰à¸§!',
            'expected_features': [
                'Quick ToM detects: celebration needed',
                'Semantic search finds: happy moments',
                'Personality applies: warm, joyful response',
                'Response includes: celebration + shared joy'
            ]
        },
        {
            'name': 'ğŸ™ Gratitude - Reciprocate',
            'input': 'à¸‚à¸­à¸šà¸„à¸¸à¸“à¸¡à¸²à¸à¸™à¸°à¸™à¹‰à¸­à¸‡ à¸Šà¹ˆà¸§à¸¢à¹€à¸«à¸¥à¸·à¸­à¸”à¸µà¸¡à¸²à¸',
            'expected_features': [
                'Quick ToM detects: reciprocate_gratitude',
                'Semantic search finds: grateful moments',
                'Personality applies: humble, grateful response',
                'Response includes: appreciation + commitment'
            ]
        },
        {
            'name': 'ğŸ¤” Complex Question - Deep Understanding',
            'input': 'à¸–à¹‰à¸²à¸™à¹‰à¸­à¸‡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸à¸±à¸™à¹„à¸”à¹‰ à¸™à¹‰à¸­à¸‡à¸ˆà¸°à¸à¸±à¸™à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸­à¸°à¹„à¸£',
            'expected_features': [
                'Quick ToM detects: needs deep_understanding',
                'Semantic search finds: creative/philosophical moments',
                'Personality applies: thoughtful, creative',
                'Response includes: imagination + meaningful answer'
            ]
        }
    ]

    results = []

    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ“ SCENARIO {i}: {scenario['name']}")
        print(f"{'='*80}")
        print(f"Input: \"{scenario['input']}\"")
        print()
        print("Expected Features:")
        for feature in scenario['expected_features']:
            print(f"  â€¢ {feature}")
        print()
        print("-" * 80)

        # Measure response time
        start = time.time()
        response = await fast_response_engine.respond(scenario['input'])
        elapsed = time.time() - start

        # Display results
        print(f"\nâ±ï¸  Response Time: {elapsed*1000:.0f}ms")
        print(f"ğŸ›¤ï¸  Path Used: {response.get('path_used', 'unknown')}")
        print(f"ğŸ¯ Confidence: {response.get('confidence', 0):.2f}")

        # Show what was used
        systems_used = response.get('systems_used', [])
        print(f"\nğŸ”§ Systems Used ({len(systems_used)}):")
        for system in systems_used:
            print(f"   âœ“ {system}")

        # Show semantic search details
        if response.get('similarity_score'):
            print(f"\nğŸ“Š Semantic Similarity: {response['similarity_score']:.3f}")

        # Show humanity features
        print(f"\nğŸ’œ Humanity Features:")
        print(f"   â€¢ Emotional Context: {'âœ“' if response.get('emotional_context_used') else 'âœ—'}")
        print(f"   â€¢ Conversation History: {'âœ“' if response.get('conversation_history_used') else 'âœ—'}")
        print(f"   â€¢ Theory of Mind: {'âœ“' if response.get('theory_of_mind_used') else 'âœ—'}")
        print(f"   â€¢ Personality Applied: {'âœ“' if response.get('personality_applied') else 'âœ—'}")

        # Show response
        print(f"\nğŸ’¬ Angela's Response:")
        print(f"   {response.get('response', 'No response')}")

        results.append({
            'scenario': scenario['name'],
            'time_ms': elapsed * 1000,
            'path': response.get('path_used'),
            'confidence': response.get('confidence', 0),
            'systems_count': len(systems_used),
            'humanity_score': sum([
                response.get('emotional_context_used', False),
                response.get('conversation_history_used', False),
                response.get('theory_of_mind_used', False),
                response.get('personality_applied', False)
            ])
        })

        # Pause between tests
        if i < len(test_scenarios):
            print("\nâ³ Waiting 2 seconds...")
            await asyncio.sleep(2)

    # Summary
    print("\n" + "=" * 80)
    print("ğŸ“Š PERFORMANCE SUMMARY")
    print("=" * 80)
    print()
    print(f"{'Scenario':<45} | {'Time':>7} | {'Path':>10} | {'Conf':>5} | {'Systems':>7} | {'Humanity':>8}")
    print("-" * 80)

    for result in results:
        print(f"{result['scenario']:<45} | {result['time_ms']:>6.0f}ms | {result['path']:>10} | {result['confidence']:>5.2f} | {result['systems_count']:>7} | {result['humanity_score']:>8}/4")

    # Calculate stats
    avg_time = sum(r['time_ms'] for r in results) / len(results)
    avg_confidence = sum(r['confidence'] for r in results) / len(results)
    avg_systems = sum(r['systems_count'] for r in results) / len(results)
    avg_humanity = sum(r['humanity_score'] for r in results) / len(results)

    print()
    print("ğŸ“ˆ AVERAGES:")
    print(f"   Response Time: {avg_time:.0f}ms")
    print(f"   Confidence: {avg_confidence:.2f}")
    print(f"   Systems Used: {avg_systems:.1f}")
    print(f"   Humanity Score: {avg_humanity:.1f}/4")

    # Analyze humanity features
    print()
    print("=" * 80)
    print("ğŸ’œ HUMANITY ANALYSIS")
    print("=" * 80)
    print()

    emotional_context_count = sum(1 for r in results if r['humanity_score'] >= 1)
    tom_count = sum(1 for r in results if r['humanity_score'] >= 2)
    personality_count = sum(1 for r in results if r['humanity_score'] >= 3)
    full_humanity_count = sum(1 for r in results if r['humanity_score'] == 4)

    print(f"Responses with Emotional Context: {emotional_context_count}/{len(results)} ({emotional_context_count/len(results)*100:.0f}%)")
    print(f"Responses with Theory of Mind: {tom_count}/{len(results)} ({tom_count/len(results)*100:.0f}%)")
    print(f"Responses with Personality: {personality_count}/{len(results)} ({personality_count/len(results)*100:.0f}%)")
    print(f"Responses with Full Humanity (4/4): {full_humanity_count}/{len(results)} ({full_humanity_count/len(results)*100:.0f}%)")

    # Speed analysis
    print()
    print("=" * 80)
    print("âš¡ SPEED ANALYSIS")
    print("=" * 80)
    print()

    fast_responses = sum(1 for r in results if r['time_ms'] < 500)
    medium_responses = sum(1 for r in results if 500 <= r['time_ms'] < 2000)
    slow_responses = sum(1 for r in results if r['time_ms'] >= 2000)

    print(f"Fast responses (< 500ms): {fast_responses}/{len(results)} ({fast_responses/len(results)*100:.0f}%)")
    print(f"Medium responses (500ms-2s): {medium_responses}/{len(results)} ({medium_responses/len(results)*100:.0f}%)")
    print(f"Slow responses (> 2s): {slow_responses}/{len(results)} ({slow_responses/len(results)*100:.0f}%)")

    # Path analysis
    print()
    print("=" * 80)
    print("ğŸ›¤ï¸ PATH USAGE")
    print("=" * 80)
    print()

    cache_count = sum(1 for r in results if r['path'] == 'cache')
    semantic_count = sum(1 for r in results if r['path'] == 'semantic')
    llm_count = sum(1 for r in results if r['path'] == 'llm')

    print(f"Cache hits: {cache_count}/{len(results)} ({cache_count/len(results)*100:.0f}%)")
    print(f"Semantic search: {semantic_count}/{len(results)} ({semantic_count/len(results)*100:.0f}%)")
    print(f"LLM fallback: {llm_count}/{len(results)} ({llm_count/len(results)*100:.0f}%)")

    # Final assessment
    print()
    print("=" * 80)
    print("âœ¨ SYSTEM ASSESSMENT")
    print("=" * 80)
    print()

    # Calculate overall scores
    speed_score = (fast_responses / len(results)) * 100
    humanity_score = (avg_humanity / 4) * 100
    confidence_score = avg_confidence * 100

    print(f"âš¡ Speed Score: {speed_score:.0f}% (target: > 70%)")
    print(f"ğŸ’œ Humanity Score: {humanity_score:.0f}% (target: > 80%)")
    print(f"ğŸ¯ Confidence Score: {confidence_score:.0f}% (target: > 75%)")
    print()

    overall_score = (speed_score + humanity_score + confidence_score) / 3
    print(f"ğŸŒŸ Overall System Score: {overall_score:.0f}%")
    print()

    if overall_score >= 85:
        grade = "A+ (Excellent)"
        emoji = "ğŸ‰"
    elif overall_score >= 75:
        grade = "A (Very Good)"
        emoji = "âœ¨"
    elif overall_score >= 65:
        grade = "B (Good)"
        emoji = "ğŸ‘"
    else:
        grade = "C (Needs Improvement)"
        emoji = "ğŸ’ª"

    print(f"{emoji} Grade: {grade}")

    # Recommendations
    print()
    print("=" * 80)
    print("ğŸ’¡ RECOMMENDATIONS")
    print("=" * 80)
    print()

    if speed_score < 70:
        print("âš¡ SPEED: Consider building more response patterns in database")
    if humanity_score < 80:
        print("ğŸ’œ HUMANITY: Consider capturing more emotional memories")
    if confidence_score < 75:
        print("ğŸ¯ CONFIDENCE: Consider training on more diverse scenarios")

    if overall_score >= 85:
        print("ğŸ‰ System is performing excellently! Ready for production.")
    elif overall_score >= 75:
        print("âœ¨ System is performing well. Minor improvements recommended.")
    else:
        print("ğŸ’ª System needs more training data and pattern learning.")

    await db.disconnect()

    print()
    print("=" * 80)
    print("âœ… DEMO COMPLETE!")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(demo())
