#!/usr/bin/env python3
"""
üíú Training Data Service (V1)
Application service for managing training data preparation and file operations.

Handles:
- Script execution for data preparation
- File management (generation, download, deletion)
- Statistics retrieval
- Quality report generation

‚úÖ [Batch-26]: Clean Architecture with DI
"""

import subprocess
import os
import json
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime
import logging

from angela_core.application.services.base_service import BaseService

logger = logging.getLogger(__name__)


class TrainingDataService(BaseService):
    """
    Service for training data preparation and management (V1).

    Orchestrates training data generation using prepare_angela_training_data.py script.
    Manages file operations and provides statistics about generated datasets.
    """

    def __init__(self):
        """Initialize TrainingDataService."""
        super().__init__()

        # Paths configuration
        self.finetuning_dir = Path("/Users/davidsamanyaporn/PycharmProjects/AngelaAI/FineTuninng_coursera")
        self.script_path = self.finetuning_dir / "prepare_angela_training_data.py"

        # File paths
        self.train_file = self.finetuning_dir / "angela_training_data.jsonl"
        self.test_file = self.finetuning_dir / "angela_test_data.jsonl"
        self.stats_file = self.finetuning_dir / "data_statistics.json"
        self.quality_file = self.finetuning_dir / "data_quality_report.txt"

        logger.info(f"‚úÖ TrainingDataService initialized (finetuning_dir: {self.finetuning_dir})")

    def get_service_name(self) -> str:
        """Get service name for logging."""
        return "TrainingDataService"

    async def prepare_training_data(
        self,
        min_importance: int = 7,
        max_per_topic: int = 150,
        test_split: float = 0.1,
        min_length: int = 10,
        time_window: int = 5
    ) -> Dict[str, Any]:
        """
        Prepare training data by running the preparation script.

        Args:
            min_importance: Minimum importance level (1-10)
            max_per_topic: Maximum examples per topic
            test_split: Test split ratio (0.0-1.0)
            min_length: Minimum message length
            time_window: Time window for conversations (minutes)

        Returns:
            Dict with:
            - success: bool
            - message: str
            - stats: dict (dataset statistics)
            - files: dict (generated file paths)

        Raises:
            RuntimeError: If script execution fails
            TimeoutError: If script takes longer than 2 minutes
        """
        operation_name = "prepare_training_data"
        await self._log_operation_start(
            operation_name,
            min_importance=min_importance,
            max_per_topic=max_per_topic,
            test_split=test_split
        )

        try:
            # Build command
            cmd = [
                "python3",
                str(self.script_path),
                "--min-importance", str(min_importance),
                "--max-per-topic", str(max_per_topic),
                "--test-split", str(test_split),
                "--min-length", str(min_length),
                "--time-window", str(time_window)
            ]

            logger.info(f"üöÄ Running data preparation script: {' '.join(cmd)}")

            # Run script with timeout
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=str(self.finetuning_dir),
                timeout=120  # 2 minutes
            )

            # Check for errors
            if result.returncode != 0:
                error_msg = f"Script failed with exit code {result.returncode}: {result.stderr}"
                logger.error(f"‚ùå {error_msg}")
                await self._log_operation_error(operation_name, Exception(error_msg))
                raise RuntimeError(error_msg)

            logger.info(f"‚úÖ Script completed successfully")

            # Read statistics
            if not self.stats_file.exists():
                raise RuntimeError("Statistics file not generated by script")

            with open(self.stats_file, 'r', encoding='utf-8') as f:
                stats = json.load(f)

            # Check file existence and get sizes
            files = {
                "training": str(self.train_file) if self.train_file.exists() else None,
                "test": str(self.test_file) if self.test_file.exists() else None,
                "statistics": str(self.stats_file),
                "quality_report": str(self.quality_file) if self.quality_file.exists() else None
            }

            file_sizes = {}
            for name, path in files.items():
                if path and os.path.exists(path):
                    size_mb = os.path.getsize(path) / (1024 * 1024)
                    file_sizes[name] = round(size_mb, 2)

            result_data = {
                "success": True,
                "message": f"‚úÖ Generated {stats.get('total_examples', 0)} examples",
                "stats": {
                    **stats,
                    "file_sizes_mb": file_sizes
                },
                "files": files
            }

            await self._log_operation_success(
                operation_name,
                examples_generated=stats.get('total_examples', 0)
            )

            return result_data

        except subprocess.TimeoutExpired:
            error_msg = "Data preparation timed out (>2 minutes)"
            logger.error(f"‚è±Ô∏è {error_msg}")
            await self._log_operation_error(operation_name, TimeoutError(error_msg))
            raise TimeoutError(error_msg)

        except Exception as e:
            logger.error(f"‚ùå Failed to prepare data: {str(e)}")
            await self._log_operation_error(operation_name, e)
            raise

    async def get_file_path(self, file_type: str) -> Optional[Path]:
        """
        Get file path for a specific file type.

        Args:
            file_type: One of 'training', 'test', 'statistics', 'quality_report'

        Returns:
            Path object if file type is valid, None otherwise

        Raises:
            ValueError: If file_type is invalid
        """
        file_map = {
            "training": self.train_file,
            "test": self.test_file,
            "statistics": self.stats_file,
            "quality_report": self.quality_file
        }

        if file_type not in file_map:
            valid_types = list(file_map.keys())
            raise ValueError(f"Invalid file type '{file_type}'. Must be one of: {valid_types}")

        file_path = file_map[file_type]

        if not file_path.exists():
            return None

        return file_path

    async def get_status(self) -> Dict[str, Any]:
        """
        Get status of training data files.

        Returns:
            Dict with:
            - files: dict (metadata for each file)
            - statistics: dict (dataset stats if available)
            - has_data: bool (whether complete dataset exists)
        """
        operation_name = "get_status"
        await self._log_operation_start(operation_name)

        try:
            files = {
                "training": self.train_file,
                "test": self.test_file,
                "statistics": self.stats_file,
                "quality_report": self.quality_file
            }

            status = {}

            for name, path in files.items():
                if path.exists():
                    stat = os.stat(path)
                    size_mb = stat.st_size / (1024 * 1024)
                    modified = datetime.fromtimestamp(stat.st_mtime)

                    status[name] = {
                        "exists": True,
                        "size_mb": round(size_mb, 2),
                        "modified": modified.isoformat(),
                        "path": str(path)
                    }
                else:
                    status[name] = {
                        "exists": False,
                        "size_mb": 0,
                        "modified": None,
                        "path": str(path)
                    }

            # Load statistics if available
            stats = None
            if self.stats_file.exists():
                try:
                    with open(self.stats_file, 'r', encoding='utf-8') as f:
                        stats = json.load(f)
                except Exception as e:
                    logger.warning(f"Failed to read statistics file: {e}")

            result = {
                "files": status,
                "statistics": stats,
                "has_data": all(status[f]["exists"] for f in ["training", "test"])
            }

            await self._log_operation_success(operation_name, has_data=result["has_data"])

            return result

        except Exception as e:
            logger.error(f"‚ùå Failed to get status: {str(e)}")
            await self._log_operation_error(operation_name, e)
            raise

    async def clear_training_data(self) -> Dict[str, Any]:
        """
        Delete all generated training data files.

        Returns:
            Dict with:
            - success: bool
            - message: str
            - deleted: list (names of deleted files)
        """
        operation_name = "clear_training_data"
        await self._log_operation_start(operation_name)

        try:
            files = [
                self.train_file,
                self.test_file,
                self.stats_file,
                self.quality_file
            ]

            deleted = []
            for file_path in files:
                if file_path.exists():
                    file_path.unlink()
                    deleted.append(file_path.name)
                    logger.info(f"üóëÔ∏è Deleted: {file_path.name}")

            result = {
                "success": True,
                "message": f"Deleted {len(deleted)} files",
                "deleted": deleted
            }

            await self._log_operation_success(operation_name, files_deleted=len(deleted))

            return result

        except Exception as e:
            logger.error(f"‚ùå Failed to clear data: {str(e)}")
            await self._log_operation_error(operation_name, e)
            raise
