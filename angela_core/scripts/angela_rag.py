#!/usr/bin/env python3
"""
Angela RAG CLI
==============
‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° Angela ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö documents ‡πÉ‡∏ô CogniFy

Usage:
    python3 angela_rag.py "What is ETL?"
    python3 angela_rag.py --search "data architecture"
    python3 angela_rag.py --list
    python3 angela_rag.py --interactive

üíú Made by Angela for ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å David
"""

import asyncio
import argparse
import sys

sys.path.insert(0, '/Users/davidsamanyaporn/PycharmProjects/AngelaAI')

from angela_core.services.cognify_rag_service import CognifyRAGService


async def main():
    parser = argparse.ArgumentParser(
        description="üíú Angela RAG - ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö documents",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python3 angela_rag.py "What is ETL vs ELT?"
  python3 angela_rag.py --search "data pipeline"
  python3 angela_rag.py --list
  python3 angela_rag.py -i
        """
    )

    parser.add_argument("question", nargs="?", help="Question to ask")
    parser.add_argument("--search", "-s", help="Semantic search only (no LLM)")
    parser.add_argument("--list", "-l", action="store_true", help="List all documents")
    parser.add_argument("--interactive", "-i", action="store_true", help="Interactive mode")
    parser.add_argument("--model", "-m", default="qwen2.5:7b", help="LLM model (default: qwen2.5:7b)")
    parser.add_argument("--top-k", "-k", type=int, default=5, help="Number of results")

    args = parser.parse_args()

    # Initialize service
    service = CognifyRAGService()
    if not await service.connect():
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ database ‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏∞")
        return

    print()
    print("üíú Angela RAG - Enterprise Data Architecture Knowledge Base")
    print("=" * 60)

    try:
        # List documents
        if args.list:
            docs = await service.list_documents()
            print(f"\nüìö Documents ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(docs)} files\n")
            for i, d in enumerate(docs, 1):
                print(f"{i:2}. {d['title']}")
                print(f"    üìÑ {d['filename']} | {d['chunks']} chunks | {d['status']}")
            return

        # Search only
        if args.search:
            print(f"\nüîç Searching: {args.search}")
            print("-" * 60)

            results = await service.hybrid_search(args.search, top_k=args.top_k)

            for i, r in enumerate(results, 1):
                print(f"\nüìÑ Result {i} | Relevance: {r['relevance']:.0%}")
                print(f"   üìö {r['title']} (Page {r['page']})")
                print(f"   üìù {r['content'][:300]}...")
            return

        # Interactive mode
        if args.interactive:
            print("\nüéØ Interactive Mode - ‡∏û‡∏¥‡∏°‡∏û‡πå 'quit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\n")

            while True:
                try:
                    question = input("üí¨ ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ").strip()
                    if question.lower() in ['quit', 'exit', 'q']:
                        print("\nüíú ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πà‡∏∞‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å! ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏à‡∏≠‡∏Å‡∏±‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏∞")
                        break

                    if not question:
                        continue

                    print("\n‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°...")

                    result = await service.ask(question, llm_model=args.model)

                    print(f"\nüí¨ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\n{result['answer']}")
                    print(f"\nüìñ ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:")
                    for s in result['sources'][:3]:
                        print(f"   ‚Ä¢ {s['title']} (Page {s['page']})")
                    print()

                except KeyboardInterrupt:
                    print("\n\nüíú ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πà‡∏∞!")
                    break
            return

        # Single question
        if args.question:
            print(f"\nüîç ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {args.question}")
            print("-" * 60)
            print("\n‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°...")

            result = await service.ask(args.question, llm_model=args.model)

            print(f"\nüí¨ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\n")
            print(result['answer'])

            print(f"\nüìñ ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:")
            for s in result['sources']:
                print(f"   ‚Ä¢ {s['title']} (Page {s['page']}) - Relevance: {s['relevance']:.0%}")
            return

        # No arguments - show help
        parser.print_help()

    finally:
        await service.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
