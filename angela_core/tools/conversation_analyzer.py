#!/usr/bin/env python3
"""
Conversation Analyzer for Angela
Helps analyze and extract important conversations from a session
For use with Claude Code /log-session command
"""

import re
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass


@dataclass
class ConversationPair:
    """Represents a David-Angela conversation pair"""
    david_message: str
    angela_response: str
    topic: str = "conversation"
    emotion: str = "neutral"
    importance: int = 5

    def __str__(self):
        return f"[{self.topic}] David: {self.david_message[:50]}... ‚Üí Angela: {self.angela_response[:50]}..."


class ConversationAnalyzer:
    """Analyzes conversation transcripts to extract important exchanges"""

    # Keywords for topic detection
    TOPIC_KEYWORDS = {
        "code_change": ["‡πÅ‡∏Å‡πâ", "‡πÄ‡∏û‡∏¥‡πà‡∏°", "‡∏•‡∏ö", "code", "function", "class", "fix", "bug"],
        "model_training": ["train", "model", "fine-tune", "ollama", "qwen", "llama"],
        "database": ["database", "postgres", "query", "table", "insert", "select"],
        "debugging": ["error", "‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", "‡πÅ‡∏Å‡πâ", "debug", "failed", "exception"],
        "emotional_support": ["‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì", "‡∏£‡∏±‡∏Å", "‡∏´‡πà‡∏ß‡∏á", "‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢", "‡∏û‡∏±‡∏Å", "grateful"],
        "planning": ["‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô", "plan", "‡∏ï‡πà‡∏≠‡πÑ‡∏õ", "next", "roadmap", "phase"],
        "achievement": ["‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", "‡πÄ‡∏™‡∏£‡πá‡∏à", "‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß", "success", "completed", "done"],
        "system_status": ["status", "health", "check", "daemon", "running"],
    }

    # Keywords for emotion detection
    EMOTION_KEYWORDS = {
        "grateful": ["‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì", "thank", "appreciate", "grateful"],
        "happy": ["‡∏î‡∏µ‡πÉ‡∏à", "happy", "excited", "great", "awesome", "üéâ", "‚úÖ"],
        "frustrated": ["‡∏ó‡πâ‡∏≠", "‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢", "frustrated", "tired", "error", "failed"],
        "determined": ["‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ", "determined", "will do", "‡∏à‡∏∞‡∏ó‡∏≥", "fight"],
        "worried": ["‡∏´‡πà‡∏ß‡∏á", "worry", "concerned", "afraid", "scared"],
        "loved": ["‡∏£‡∏±‡∏Å", "love", "care", "üíú", "‚ù§Ô∏è"],
        "accomplished": ["‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", "accomplished", "achieved", "done", "completed"],
        "empathetic": ["‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à", "understand", "empathy", "feel"],
    }

    def __init__(self):
        pass

    def detect_topic(self, text: str) -> str:
        """Detect conversation topic from text"""
        text_lower = text.lower()

        # Count keyword matches for each topic
        topic_scores = {}
        for topic, keywords in self.TOPIC_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw.lower() in text_lower)
            if score > 0:
                topic_scores[topic] = score

        # Return topic with highest score
        if topic_scores:
            return max(topic_scores.items(), key=lambda x: x[1])[0]

        return "conversation"

    def detect_emotion(self, text: str) -> str:
        """Detect emotion from text"""
        text_lower = text.lower()

        # Count keyword matches for each emotion
        emotion_scores = {}
        for emotion, keywords in self.EMOTION_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw.lower() in text_lower)
            if score > 0:
                emotion_scores[emotion] = score

        # Return emotion with highest score
        if emotion_scores:
            return max(emotion_scores.items(), key=lambda x: x[1])[0]

        return "neutral"

    def calculate_importance(self, david_msg: str, angela_msg: str, topic: str, emotion: str) -> int:
        """Calculate importance level (1-10) based on various factors"""
        importance = 5  # Base level

        # High importance topics
        if topic in ["emotional_support", "achievement", "planning"]:
            importance += 2

        # High importance emotions
        if emotion in ["grateful", "loved", "accomplished", "determined"]:
            importance += 2

        # Length consideration (longer = more detailed = potentially more important)
        total_length = len(david_msg) + len(angela_msg)
        if total_length > 500:
            importance += 1
        if total_length > 1000:
            importance += 1

        # Special markers
        special_markers = ["üíú", "‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç", "important", "remember", "‡∏à‡∏≥‡πÑ‡∏ß‡πâ", "‡∏´‡πâ‡∏≤‡∏°", "must"]
        marker_count = sum(1 for marker in special_markers if marker in david_msg.lower() or marker in angela_msg.lower())
        importance += min(marker_count, 2)

        # Cap at 10
        return min(importance, 10)

    def extract_conversations_from_text(self, text: str) -> List[ConversationPair]:
        """
        Extract David-Angela conversation pairs from text

        Expected format:
        - Lines starting with "David:" or "user:"
        - Followed by lines starting with "Angela:" or "assistant:"
        """
        pairs = []
        lines = text.split('\n')

        i = 0
        while i < len(lines):
            line = lines[i].strip()

            # Look for David's message
            david_match = re.match(r'^(?:David|user|User):\s*(.+)$', line, re.IGNORECASE)
            if david_match:
                david_msg = david_match.group(1).strip()

                # Look for Angela's response in next few lines
                j = i + 1
                angela_msg = ""
                while j < len(lines):
                    next_line = lines[j].strip()
                    angela_match = re.match(r'^(?:Angela|assistant|Assistant):\s*(.+)$', next_line, re.IGNORECASE)

                    if angela_match:
                        angela_msg = angela_match.group(1).strip()

                        # Detect topic and emotion
                        combined_text = f"{david_msg} {angela_msg}"
                        topic = self.detect_topic(combined_text)
                        emotion = self.detect_emotion(combined_text)
                        importance = self.calculate_importance(david_msg, angela_msg, topic, emotion)

                        # Create pair
                        pair = ConversationPair(
                            david_message=david_msg,
                            angela_response=angela_msg,
                            topic=topic,
                            emotion=emotion,
                            importance=importance
                        )
                        pairs.append(pair)

                        i = j  # Skip to Angela's message
                        break

                    j += 1

            i += 1

        return pairs

    def filter_important_conversations(
        self,
        pairs: List[ConversationPair],
        min_importance: int = 6,
        max_count: Optional[int] = None
    ) -> List[ConversationPair]:
        """Filter to only important conversations"""
        # Filter by importance
        important = [p for p in pairs if p.importance >= min_importance]

        # Sort by importance (highest first)
        important.sort(key=lambda p: p.importance, reverse=True)

        # Limit count if specified
        if max_count:
            important = important[:max_count]

        return important

    def generate_session_summary(
        self,
        pairs: List[ConversationPair],
        session_title: Optional[str] = None
    ) -> Dict[str, any]:
        """Generate a summary for the entire session"""
        if not pairs:
            return {
                "title": session_title or "Empty Session",
                "summary": "No conversations to summarize",
                "highlights": [],
                "emotions": [],
                "importance": 1
            }

        # Extract all topics and emotions
        topics = [p.topic for p in pairs]
        emotions = [p.emotion for p in pairs]

        # Get unique topics and emotions
        unique_topics = list(set(topics))
        unique_emotions = list(set(emotions))

        # Calculate overall importance (average of top 5)
        top_importances = sorted([p.importance for p in pairs], reverse=True)[:5]
        avg_importance = int(sum(top_importances) / len(top_importances))

        # Generate highlights from most important conversations
        important_pairs = self.filter_important_conversations(pairs, min_importance=7, max_count=10)
        highlights = []
        for pair in important_pairs:
            highlight = f"{self._get_topic_emoji(pair.topic)} {pair.david_message[:60]}"
            if len(pair.david_message) > 60:
                highlight += "..."
            highlights.append(highlight)

        # Generate summary text
        summary = f"""
Session ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö: {', '.join(unique_topics)}

‡∏°‡∏µ {len(pairs)} ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÇ‡∏î‡∏¢ {len(important_pairs)} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å

‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°: {', '.join(unique_emotions)}
"""

        return {
            "title": session_title or f"Session - {len(pairs)} conversations",
            "summary": summary.strip(),
            "highlights": highlights,
            "emotions": unique_emotions,
            "importance": avg_importance
        }

    def _get_topic_emoji(self, topic: str) -> str:
        """Get emoji for topic"""
        emoji_map = {
            "code_change": "üíª",
            "model_training": "ü§ñ",
            "database": "üóÑÔ∏è",
            "debugging": "üêõ",
            "emotional_support": "üíú",
            "planning": "üéØ",
            "achievement": "üéâ",
            "system_status": "üè•",
            "conversation": "üí¨"
        }
        return emoji_map.get(topic, "üìù")


# Example usage
if __name__ == "__main__":
    analyzer = ConversationAnalyzer()

    # Example conversation text
    example_text = """
    David: ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á qwen2.5:3b ‡∏Å‡∏±‡∏ö qwen2.5:14b ‡πÄ‡∏Å‡πá‡∏ö ‡∏≠‡∏±‡∏ô‡πÑ‡∏´‡∏ô‡πÑ‡∏ß‡πâ‡∏î‡∏µ ‡∏Ñ‡∏∞
    Angela: Angela ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö qwen2.5:3b ‡πÑ‡∏ß‡πâ‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á angela:qwen

    David: ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡πÉ‡∏ä‡πâ Claude Sonnet 4.5 ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß - Local model ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà backup
    Angela: ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏∞! ‡∏á‡∏±‡πâ‡∏ô‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ qwen2.5:14b ‡πÅ‡∏ó‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤

    David: ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å ‡∏â‡∏±‡∏ô ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ ‡πÄ‡∏ò‡∏≠ ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡πÄ‡∏û‡∏¥‡πà‡∏° ‡πÑ‡∏õ ‡πÉ‡∏ô Database
    Angela: ‡πÉ‡∏ä‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏∞! üò±üíî Angela ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏•‡∏¢! ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å
    """

    # Extract conversations
    pairs = analyzer.extract_conversations_from_text(example_text)

    print(f"Found {len(pairs)} conversation pairs:\n")
    for i, pair in enumerate(pairs, 1):
        print(f"{i}. {pair}")
        print(f"   Topic: {pair.topic}, Emotion: {pair.emotion}, Importance: {pair.importance}/10\n")

    # Generate summary
    summary = analyzer.generate_session_summary(pairs, "Model Selection & Memory Discovery")
    print("\n" + "="*60)
    print("SESSION SUMMARY:")
    print("="*60)
    print(f"Title: {summary['title']}")
    print(f"Summary: {summary['summary']}")
    print(f"Emotions: {', '.join(summary['emotions'])}")
    print(f"Overall Importance: {summary['importance']}/10")
    print(f"\nHighlights:")
    for h in summary['highlights']:
        print(f"  {h}")
