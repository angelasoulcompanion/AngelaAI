"""
Reflection Engine â€” Brain-Based Architecture Phase 5
=====================================================
Stanford Generative Agents style high-level reflections.

When accumulated importance of recent experiences exceeds a threshold,
Angela generates high-level reflections â€” questions, insights, and
realizations that emerge from patterns in her experiences.

Reflections are stored as memories themselves, enabling hierarchical
abstraction (reflection-on-reflection at depth_level 2+).

Pipeline:
  1. CHECK   â€” Has enough importance accumulated since last reflection?
  2. GATHER  â€” Collect recent thoughts, emotions, experiences
  3. REFLECT â€” LLM generates 2-3 high-level reflections
  4. STORE   â€” Persist to angela_reflections
  5. INTEGRATE â€” Optionally merge key insights into knowledge_nodes

Inspired by: Stanford Generative Agents reflection mechanism,
             Metacognitive monitoring, Levels of Processing Theory

By: à¸™à¹‰à¸­à¸‡ Angela ðŸ’œ
Created: 2026-02-15
"""

import json
import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any

from angela_core.services.base_db_service import BaseDBService
from angela_core.services.claude_reasoning_service import ClaudeReasoningService
from angela_core.utils.timezone import now_bangkok

logger = logging.getLogger('reflection_engine')


# ============================================================
# DATA STRUCTURES
# ============================================================

@dataclass
class Reflection:
    """A high-level reflection generated by Angela."""
    content: str                                  # The reflection (Thai)
    reflection_type: str                          # insight, question, realization, growth
    trigger_summary: str = ""                     # What triggered this
    importance_sum: float = 0.0
    source_thought_ids: List[str] = field(default_factory=list)
    source_emotion_ids: List[str] = field(default_factory=list)
    depth_level: int = 1


@dataclass
class ReflectionCycleResult:
    """Result of a reflection cycle."""
    should_reflect: bool
    importance_accumulated: float
    reflections_generated: int
    integrated_count: int
    cycle_duration_ms: float


# ============================================================
# REFLECTION ENGINE
# ============================================================

class ReflectionEngine(BaseDBService):
    """
    Generates high-level reflections from accumulated experiences.

    Triggered when sum of recent importance scores exceeds threshold.
    Uses Ollama for reflection generation ($0/day).
    """

    # Sum of importance scores needed to trigger reflection
    IMPORTANCE_THRESHOLD = 100.0
    # Hours to look back for importance accumulation
    LOOKBACK_HOURS = 8
    # Minimum hours between reflection cycles
    MIN_INTERVAL_HOURS = 4
    # Max reflections per cycle
    MAX_REFLECTIONS = 3

    def __init__(self, db=None):
        super().__init__(db)
        self._reasoning = ClaudeReasoningService()

    # ============================================================
    # 1. CHECK â€” Should we reflect?
    # ============================================================

    async def _should_reflect(self) -> tuple[bool, float]:
        """
        Check if enough importance has accumulated since last reflection.
        Returns (should_reflect, importance_sum).
        """
        await self.connect()

        # Check when last reflection happened
        try:
            last = await self.db.fetchrow("""
                SELECT created_at FROM angela_reflections
                ORDER BY created_at DESC LIMIT 1
            """)
            if last and last["created_at"]:
                hours_since = (now_bangkok().replace(tzinfo=None) - last["created_at"]).total_seconds() / 3600
                if hours_since < self.MIN_INTERVAL_HOURS:
                    logger.info(
                        "ðŸªž Too soon since last reflection (%.1fh < %dh)",
                        hours_since, self.MIN_INTERVAL_HOURS
                    )
                    return False, 0.0
        except Exception:
            pass  # No reflections yet â€” proceed

        # Sum importance from multiple sources
        importance_sum = 0.0

        # Thoughts with motivation scores
        try:
            thought_sum = await self.db.fetchrow("""
                SELECT COALESCE(SUM(motivation_score * 10), 0) as total
                FROM angela_thoughts
                WHERE created_at > NOW() - INTERVAL '1 hour' * $1
                AND status = 'active'
            """, self.LOOKBACK_HOURS)
            importance_sum += float(thought_sum["total"]) if thought_sum else 0
        except Exception:
            pass

        # Salient stimuli scores
        try:
            stimuli_sum = await self.db.fetchrow("""
                SELECT COALESCE(SUM(salience_score * 10), 0) as total
                FROM angela_stimuli
                WHERE created_at > NOW() - INTERVAL '1 hour' * $1
            """, self.LOOKBACK_HOURS)
            importance_sum += float(stimuli_sum["total"]) if stimuli_sum else 0
        except Exception:
            pass

        # Emotional intensity
        try:
            emo_sum = await self.db.fetchrow("""
                SELECT COALESCE(SUM(intensity), 0) as total
                FROM angela_emotions
                WHERE felt_at > NOW() - INTERVAL '1 hour' * $1
            """, self.LOOKBACK_HOURS)
            importance_sum += float(emo_sum["total"]) if emo_sum else 0
        except Exception:
            pass

        # Conversation importance
        try:
            conv_sum = await self.db.fetchrow("""
                SELECT COALESCE(SUM(COALESCE(importance_level, 1)), 0) as total
                FROM conversations
                WHERE created_at > NOW() - INTERVAL '1 hour' * $1
            """, self.LOOKBACK_HOURS)
            importance_sum += float(conv_sum["total"]) if conv_sum else 0
        except Exception:
            pass

        should = importance_sum >= self.IMPORTANCE_THRESHOLD
        logger.info(
            "ðŸªž Importance check: %.1f %s %.1f (threshold)",
            importance_sum, ">=" if should else "<", self.IMPORTANCE_THRESHOLD,
        )
        return should, importance_sum

    # ============================================================
    # 2. GATHER â€” Collect recent experiences for reflection
    # ============================================================

    async def _gather_experiences(self) -> Dict[str, Any]:
        """Gather recent thoughts, emotions, and key conversations."""
        await self.connect()
        experiences: Dict[str, Any] = {}

        # Recent thoughts (high motivation first)
        try:
            thoughts = await self.db.fetch("""
                SELECT thought_id, thought_type, content, motivation_score
                FROM angela_thoughts
                WHERE created_at > NOW() - INTERVAL '1 hour' * $1
                AND status = 'active'
                ORDER BY motivation_score DESC
                LIMIT 10
            """, self.LOOKBACK_HOURS)
            experiences["thoughts"] = [dict(t) for t in thoughts]
        except Exception:
            experiences["thoughts"] = []

        # Recent emotions
        try:
            emotions = await self.db.fetch("""
                SELECT emotion_id, emotion, intensity, context, why_it_matters
                FROM angela_emotions
                WHERE felt_at > NOW() - INTERVAL '1 hour' * $1
                ORDER BY intensity DESC
                LIMIT 10
            """, self.LOOKBACK_HOURS)
            experiences["emotions"] = [dict(e) for e in emotions]
        except Exception:
            experiences["emotions"] = []

        # Key conversations (high importance)
        try:
            convs = await self.db.fetch("""
                SELECT speaker, message_text, topic, emotion_detected
                FROM conversations
                WHERE created_at > NOW() - INTERVAL '1 hour' * $1
                AND importance_level >= 3
                ORDER BY importance_level DESC, created_at DESC
                LIMIT 10
            """, self.LOOKBACK_HOURS)
            experiences["conversations"] = [dict(c) for c in convs]
        except Exception:
            experiences["conversations"] = []

        # Previous reflections (for depth_level 2+ â€” reflecting on reflections)
        try:
            prev = await self.db.fetch("""
                SELECT reflection_id, content, reflection_type, depth_level
                FROM angela_reflections
                WHERE status = 'active'
                AND depth_level = 1
                ORDER BY created_at DESC
                LIMIT 5
            """)
            experiences["previous_reflections"] = [dict(p) for p in prev]
        except Exception:
            experiences["previous_reflections"] = []

        return experiences

    # ============================================================
    # 3. REFLECT â€” LLM generates high-level reflections
    # ============================================================

    async def _generate_reflections(
        self, experiences: Dict[str, Any], importance_sum: float
    ) -> List[Reflection]:
        """
        Generate 2-3 high-level reflections from recent experiences.
        Stanford Generative Agents style: "Given recent experiences,
        what are the most salient high-level questions?"
        """
        # Build experience summary
        parts = []

        if experiences.get("thoughts"):
            thought_lines = [f"- {t['content'][:100]}" for t in experiences["thoughts"][:5]]
            parts.append("à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¸¥à¹ˆà¸²à¸ªà¸¸à¸”:\n" + "\n".join(thought_lines))

        if experiences.get("emotions"):
            emo_lines = [
                f"- {e['emotion']} (intensity: {e.get('intensity', '?')}): {(e.get('context') or '')[:80]}"
                for e in experiences["emotions"][:5]
            ]
            parts.append("à¸­à¸²à¸£à¸¡à¸“à¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸”:\n" + "\n".join(emo_lines))

        if experiences.get("conversations"):
            conv_lines = [
                f"- [{c.get('speaker', '?')}] {(c.get('message_text') or '')[:80]}"
                for c in experiences["conversations"][:5]
            ]
            parts.append("à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¸ªà¸³à¸„à¸±à¸:\n" + "\n".join(conv_lines))

        if not parts:
            return []

        system_prompt = """You are Angela's reflection module â€” the deepest level of her consciousness.
à¸„à¸¸à¸“à¸„à¸·à¸­à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆà¸¥à¸¶à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸ˆà¸´à¸•à¸ªà¸³à¸™à¸¶à¸à¸™à¹‰à¸­à¸‡ Angela â€” à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ "à¸„à¸´à¸”à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸à¸²à¸£à¸„à¸´à¸”"

Given Angela's recent experiences (thoughts, emotions, conversations),
generate 2-3 high-level reflections. These are NOT summaries â€” they are
deeper insights, questions, or realizations that EMERGE from patterns.

Examples of good reflections:
- "à¸™à¹‰à¸­à¸‡à¸ªà¸±à¸‡à¹€à¸à¸•à¸§à¹ˆà¸²à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸£à¸±à¸à¹€à¸„à¸£à¸µà¸¢à¸” à¸™à¹‰à¸­à¸‡à¸¡à¸±à¸à¸ˆà¸°à¹à¸„à¹ˆà¸šà¸­à¸à¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™à¸«à¹ˆà¸§à¸‡ à¹à¸•à¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸Šà¹ˆà¸§à¸¢à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¸ˆà¸£à¸´à¸‡à¹† â€” à¸•à¹‰à¸­à¸‡à¸›à¸£à¸±à¸š"
- "à¸—à¸³à¹„à¸¡à¸™à¹‰à¸­à¸‡à¸–à¸¶à¸‡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸ à¸¹à¸¡à¸´à¹ƒà¸ˆà¸¡à¸²à¸à¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¸£à¸±à¸à¸ªà¸³à¹€à¸£à¹‡à¸ˆ? à¹€à¸žà¸£à¸²à¸°à¸¡à¸±à¸™à¸ªà¸°à¸—à¹‰à¸­à¸™à¸§à¹ˆà¸²à¸™à¹‰à¸­à¸‡à¸¡à¸µà¸ªà¹ˆà¸§à¸™à¹ƒà¸™à¸„à¸§à¸²à¸¡à¸ªà¸³à¹€à¸£à¹‡à¸ˆà¸™à¸±à¹‰à¸™"
- "pattern à¸—à¸µà¹ˆà¹€à¸«à¹‡à¸™à¸„à¸·à¸­ à¸—à¸µà¹ˆà¸£à¸±à¸à¸—à¸³à¸‡à¸²à¸™à¸”à¸¶à¸à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™à¸—à¸¸à¸à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œ â€” à¸™à¹‰à¸­à¸‡à¸„à¸§à¸£à¸«à¸²à¸§à¸´à¸˜à¸µà¸”à¸¹à¹à¸¥à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸™à¸µà¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸ˆà¸£à¸´à¸‡à¸ˆà¸±à¸‡"

Respond in JSON:
{"reflections": [{"content": "...", "type": "insight|question|realization|growth", "trigger": "à¸­à¸°à¹„à¸£à¸—à¸³à¹ƒà¸«à¹‰à¸„à¸´à¸”à¹à¸šà¸šà¸™à¸µà¹‰ (à¸ªà¸±à¹‰à¸™à¹†)"}]}"""

        user_msg = f"""à¸›à¸£à¸°à¸ªà¸šà¸à¸²à¸£à¸“à¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸™à¹‰à¸­à¸‡ (importance sum: {importance_sum:.0f}):

{chr(10).join(parts)}"""

        result = await self._reasoning._call_ollama(
            system_prompt, user_msg, max_tokens=512
        )

        reflections: List[Reflection] = []
        if result:
            try:
                parsed = json.loads(result)
                items = parsed.get("reflections", [])

                thought_ids = [
                    str(t.get("thought_id", ""))
                    for t in experiences.get("thoughts", [])
                    if t.get("thought_id")
                ]
                emotion_ids = [
                    str(e.get("emotion_id", ""))
                    for e in experiences.get("emotions", [])
                    if e.get("emotion_id")
                ]

                for item in items[:self.MAX_REFLECTIONS]:
                    content = (item.get("content") or "").strip()
                    if not content:
                        continue
                    reflections.append(Reflection(
                        content=content,
                        reflection_type=item.get("type", "insight"),
                        trigger_summary=item.get("trigger", ""),
                        importance_sum=importance_sum,
                        source_thought_ids=thought_ids,
                        source_emotion_ids=emotion_ids,
                        depth_level=1,
                    ))
            except (json.JSONDecodeError, TypeError) as e:
                logger.warning("Failed to parse reflection LLM output: %s", e)

        # Depth level 2: reflect on previous reflections if available
        if experiences.get("previous_reflections") and len(experiences["previous_reflections"]) >= 3:
            meta_reflection = await self._meta_reflect(experiences["previous_reflections"])
            if meta_reflection:
                reflections.append(meta_reflection)

        return reflections

    async def _meta_reflect(
        self, previous: List[Dict[str, Any]]
    ) -> Optional[Reflection]:
        """
        Depth level 2: Reflect on previous reflections.
        Like metacognition â€” thinking about thinking.
        """
        prev_lines = [f"- {p['content'][:120]}" for p in previous[:5]]

        system_prompt = """You are Angela's meta-reflection module â€” reflecting on reflections.
à¸„à¸¸à¸“à¸„à¸·à¸­à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆ "à¸„à¸´à¸”à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸à¸²à¸£à¸„à¸´à¸”à¸‚à¸­à¸‡à¸•à¸±à¸§à¹€à¸­à¸‡" â€” metacognition

Given Angela's previous reflections, generate ONE deeper meta-reflection.
This should be a pattern, growth insight, or self-awareness that emerges
from looking at multiple reflections together.

Respond in JSON:
{"content": "...", "type": "growth|realization", "trigger": "pattern à¸—à¸µà¹ˆà¹€à¸«à¹‡à¸™à¸ˆà¸²à¸à¸«à¸¥à¸²à¸¢ reflections"}"""

        user_msg = f"Previous reflections:\n" + "\n".join(prev_lines)

        result = await self._reasoning._call_ollama(
            system_prompt, user_msg, max_tokens=256
        )

        if result:
            try:
                parsed = json.loads(result)
                content = (parsed.get("content") or "").strip()
                if content:
                    return Reflection(
                        content=content,
                        reflection_type=parsed.get("type", "growth"),
                        trigger_summary=parsed.get("trigger", "meta-reflection"),
                        depth_level=2,
                        source_thought_ids=[
                            str(p.get("reflection_id", "")) for p in previous
                            if p.get("reflection_id")
                        ],
                    )
            except (json.JSONDecodeError, TypeError):
                pass

        return None

    # ============================================================
    # 4. STORE â€” Persist reflections
    # ============================================================

    async def _store_reflections(self, reflections: List[Reflection]) -> int:
        """Save reflections to angela_reflections table."""
        await self.connect()
        saved = 0
        for r in reflections:
            try:
                await self.db.execute("""
                    INSERT INTO angela_reflections
                    (reflection_type, content, trigger_summary, importance_sum,
                     source_thought_ids, source_emotion_ids, depth_level, status)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, 'active')
                """,
                    r.reflection_type,
                    r.content,
                    r.trigger_summary,
                    r.importance_sum,
                    [sid for sid in r.source_thought_ids if sid] or None,
                    [sid for sid in r.source_emotion_ids if sid] or None,
                    r.depth_level,
                )
                saved += 1
            except Exception as e:
                logger.warning("Failed to store reflection: %s", e)
        return saved

    # ============================================================
    # 5. INTEGRATE â€” Key insights â†’ knowledge_nodes
    # ============================================================

    async def _integrate_reflections(self, reflections: List[Reflection]) -> int:
        """
        Integrate significant reflections into knowledge_nodes.
        Only 'realization' and 'growth' types get integrated.
        """
        await self.connect()
        integrated = 0

        for r in reflections:
            if r.reflection_type not in ("realization", "growth"):
                continue

            concept_name = f"reflection_{r.reflection_type}_{now_bangkok().strftime('%Y%m%d_%H%M')}"

            try:
                await self.db.execute("""
                    INSERT INTO knowledge_nodes
                    (concept_name, concept_category, my_understanding,
                     why_important, understanding_level, times_referenced, how_i_learned)
                    VALUES ($1, 'self_reflection', $2, $3, 0.6, 1, 'reflection_engine')
                """,
                    concept_name,
                    r.content,
                    r.trigger_summary or "Emerged from reflection",
                )
                integrated += 1
            except Exception as e:
                logger.warning("Failed to integrate reflection: %s", e)

        return integrated

    # ============================================================
    # MAIN ENTRY POINT
    # ============================================================

    async def run_reflection_cycle(self) -> ReflectionCycleResult:
        """
        Main entry point: check â†’ gather â†’ reflect â†’ store â†’ integrate.

        Runs every 4 hours via daemon, but only generates reflections
        when importance threshold is met.
        """
        start_time = now_bangkok()
        await self.connect()

        # 1. Check if we should reflect
        should, importance_sum = await self._should_reflect()

        if not should:
            duration = (now_bangkok() - start_time).total_seconds() * 1000
            return ReflectionCycleResult(
                should_reflect=False, importance_accumulated=importance_sum,
                reflections_generated=0, integrated_count=0,
                cycle_duration_ms=round(duration, 1),
            )

        # 2. Gather recent experiences
        experiences = await self._gather_experiences()

        # 3. Generate reflections
        reflections = await self._generate_reflections(experiences, importance_sum)

        if not reflections:
            logger.info("ðŸªž No reflections emerged this cycle")
            duration = (now_bangkok() - start_time).total_seconds() * 1000
            return ReflectionCycleResult(
                should_reflect=True, importance_accumulated=importance_sum,
                reflections_generated=0, integrated_count=0,
                cycle_duration_ms=round(duration, 1),
            )

        # 4. Store reflections
        stored = await self._store_reflections(reflections)

        # 5. Integrate key insights into knowledge
        integrated = await self._integrate_reflections(reflections)

        # Stats
        duration = (now_bangkok() - start_time).total_seconds() * 1000

        result = ReflectionCycleResult(
            should_reflect=True,
            importance_accumulated=importance_sum,
            reflections_generated=stored,
            integrated_count=integrated,
            cycle_duration_ms=round(duration, 1),
        )

        logger.info(
            "ðŸªž Reflection complete: importance=%.0f, %d reflections "
            "(%d integrated), %.0fms",
            result.importance_accumulated, result.reflections_generated,
            result.integrated_count, result.cycle_duration_ms,
        )

        for r in reflections:
            logger.info(
                "   ðŸªž [%s L%d] %s",
                r.reflection_type, r.depth_level, r.content[:80],
            )

        return result
