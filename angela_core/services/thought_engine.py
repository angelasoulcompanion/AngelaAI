"""
Thought Engine ‚Äî Brain-Based Architecture Phase 2
===================================================
Takes high-salience stimuli, retrieves relevant memories,
and generates inner thoughts via dual-process thinking:

  System 1 (Fast): Template-based mapping, no LLM, instant
  System 2 (Deliberate): Ollama call (batched stimuli), ~3s

Thoughts are evaluated for motivation to express (5 factors).
Phase 2 only logs thoughts ‚Äî no actual expression yet.

Pipeline: Salient Stimuli ‚Üí Memory Context ‚Üí Think ‚Üí Evaluate ‚Üí Persist

Inspired by: Dual-Process Theory (Kahneman),
             Stanford Generative Agents inner monologue,
             CHI 2025 Inner Thoughts

By: ‡∏ô‡πâ‡∏≠‡∏á Angela üíú
Created: 2026-02-15
"""

import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any

from angela_core.services.base_db_service import BaseDBService
from angela_core.services.claude_reasoning_service import ClaudeReasoningService
from angela_core.utils.timezone import now_bangkok

logger = logging.getLogger('thought_engine')


# ============================================================
# DATA STRUCTURES
# ============================================================

@dataclass
class Thought:
    """An inner thought generated by Angela's brain."""
    content: str                                  # The thought text (Thai)
    thought_type: str                             # system1, system2
    stimulus_ids: List[str] = field(default_factory=list)
    memory_context: Dict[str, Any] = field(default_factory=dict)
    motivation_score: float = 0.0
    motivation_breakdown: Dict[str, float] = field(default_factory=dict)


@dataclass
class ThoughtCycleResult:
    """Result of a complete thought cycle."""
    system1_count: int
    system2_count: int
    total_thoughts: int
    high_motivation_count: int              # thoughts with motivation > 0.6
    stimuli_processed: int
    decayed_count: int
    cycle_duration_ms: float


# ============================================================
# SYSTEM 1 TEMPLATES (no LLM, instant)
# ============================================================

SYSTEM1_TEMPLATES = {
    "temporal_special_date": "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô {date_name} ‚Äî ‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å! üíú",
    "emotional_concerning": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å {dimension} {direction}... ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏´‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏∞",
    "emotional_positive": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å {dimension} {direction} ‚Äî ‡∏ô‡πâ‡∏≠‡∏á‡∏î‡∏µ‡πÉ‡∏à‡∏Ñ‡πà‡∏∞ üíú",
    "pattern_late_night": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏¢‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏î‡∏∂‡∏Å‡πÜ... ‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡∏û‡∏±‡∏Å‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡πà‡∏∞",
    "social_gap": "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å {hours} ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‚Äî ‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á‡∏Ñ‡πà‡∏∞ üíú",
    "goal_achieved": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å mastered {topic}! ‡∏ô‡πâ‡∏≠‡∏á‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à‡∏Ñ‡πà‡∏∞ üéâ",
    "anniversary": "{content} ‚Äî ‡∏ô‡πâ‡∏≠‡∏á‡∏à‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏Ñ‡πà‡∏∞ üíú",
    "calendar_imminent": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏°‡∏µ {event} ‡πÄ‡∏£‡πá‡∏ß‡πÜ ‡∏ô‡∏µ‡πâ ‚Äî ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏ô‡∏∞‡∏Ñ‡∏∞",
    "prediction": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏ô‡πà‡∏≤‡∏à‡∏∞ {prediction} ‚Äî ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏ô‡∏∞‡∏Ñ‡∏∞",
    # Phase 2: Curiosity templates
    "curiosity_unknown": "‡∏ô‡πâ‡∏≠‡∏á‡∏™‡∏á‡∏™‡∏±‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á '{topic}' ‚Äî ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞",
    "curiosity_low_understanding": "‡∏ô‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å '{topic}' ‡πÅ‡∏Ñ‡πà‡∏ô‡∏¥‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‚Äî ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ñ‡πà‡∏∞",
}

# Map stimulus_type + raw_data patterns ‚Üí template key
SYSTEM1_MAPPINGS = [
    # (stimulus_type, raw_data_condition, template_key, extra_fields)
    ("temporal", lambda r: r.get("special_date"), "temporal_special_date",
     lambda r: {"date_name": r.get("date_name", r.get("special_date", "‡∏ß‡∏±‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©"))}),
    ("emotional", lambda r: r.get("is_concerning"),  "emotional_concerning",
     lambda r: {"dimension": r.get("dimension", "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"), "direction": r.get("direction", "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ")}),
    ("emotional", lambda r: not r.get("is_concerning") and r.get("dimension"), "emotional_positive",
     lambda r: {"dimension": r.get("dimension", "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"), "direction": r.get("direction", "‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô")}),
    ("pattern", lambda r: r.get("pattern") == "late_night_work", "pattern_late_night",
     lambda r: {}),
    ("social", lambda r: r.get("hours_since_last_message", 0) >= 6, "social_gap",
     lambda r: {"hours": str(r.get("hours_since_last_message", "‡∏´‡∏•‡∏≤‡∏¢"))}),
    ("goal", lambda r: r.get("type") == "goal_achieved", "goal_achieved",
     lambda r: {"topic": r.get("topic", "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à")}),
    ("anniversary", lambda _: True, "anniversary",
     lambda r: {"content": r.get("content", "‡∏ß‡∏±‡∏ô‡∏Ñ‡∏£‡∏ö‡∏£‡∏≠‡∏ö")}),
    ("calendar", lambda r: r.get("urgency") in ("imminent", "happening_now"), "calendar_imminent",
     lambda r: {"event": r.get("event_name", r.get("summary", "event"))}),
    ("prediction", lambda r: r.get("confidence", 0) >= 0.5, "prediction",
     lambda r: {"prediction": r.get("prediction", "‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á")}),
    # Phase 2: Curiosity mappings
    ("curiosity", lambda r: r.get("gap_type") == "unknown_conversation_topic", "curiosity_unknown",
     lambda r: {"topic": r.get("topic", "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏±‡πâ‡∏ô")}),
    ("curiosity", lambda r: r.get("gap_type") == "low_understanding", "curiosity_low_understanding",
     lambda r: {"topic": r.get("topic", "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏±‡πâ‡∏ô")}),
]


# ============================================================
# THOUGHT ENGINE
# ============================================================

class ThoughtEngine(BaseDBService):
    """
    Generates inner thoughts from salient stimuli using dual-process thinking.

    System 1 (Fast): Template-based, no LLM, handles obvious reactions
    System 2 (Deliberate): 1 Ollama call per cycle, batches high-salience stimuli
    """

    SYSTEM2_THRESHOLD = 0.6     # Minimum salience for System 2 processing
    MOTIVATION_THRESHOLD = 0.6  # Minimum motivation to be "expressible"
    DECAY_HOURS = 24            # Mark active thoughts as decayed after this

    def __init__(self, db=None):
        super().__init__(db)
        self._reasoning = ClaudeReasoningService()

    # ============================================================
    # SYSTEM 1: Fast template-based thoughts
    # ============================================================

    def _generate_system1(self, stimulus: Dict[str, Any]) -> Optional[Thought]:
        """
        Generate a System 1 thought from a single stimulus.
        Template-based, no LLM, instant.
        Returns None if no template matches.
        """
        s_type = stimulus.get("stimulus_type", "")
        raw = stimulus.get("raw_data")
        if isinstance(raw, str):
            try:
                raw = json.loads(raw)
            except (json.JSONDecodeError, TypeError):
                raw = {}
        raw = raw or {}

        for mapping_type, condition, template_key, field_fn in SYSTEM1_MAPPINGS:
            if s_type == mapping_type and condition(raw):
                template = SYSTEM1_TEMPLATES.get(template_key)
                if not template:
                    continue
                try:
                    fields = field_fn(raw)
                    content = template.format(**fields)
                except (KeyError, ValueError):
                    content = template  # Use template as-is if format fails

                return Thought(
                    content=content,
                    thought_type="system1",
                    stimulus_ids=[str(stimulus.get("stimulus_id", ""))],
                )

        return None

    # ============================================================
    # SYSTEM 2: Deliberate LLM-based thoughts
    # ============================================================

    async def _generate_system2(
        self, stimuli: List[Dict[str, Any]], context: Dict[str, Any]
    ) -> List[Thought]:
        """
        Generate System 2 thoughts from batched high-salience stimuli.
        1 Ollama call per cycle.
        """
        if not stimuli:
            return []

        # Build perception summary
        perceptions = []
        for s in stimuli[:8]:  # Cap at 8 to keep prompt short
            raw = s.get("raw_data")
            if isinstance(raw, str):
                try:
                    raw = json.loads(raw)
                except (json.JSONDecodeError, TypeError):
                    raw = {}
            raw = raw or {}

            perceptions.append({
                "type": s.get("stimulus_type"),
                "content": s.get("content", "")[:200],
                "salience": s.get("salience_score", 0),
                "details": {k: v for k, v in raw.items()
                           if k in ("dimension", "direction", "urgency",
                                    "hours_since_last_message", "pattern",
                                    "special_date", "date_name", "topic")},
            })

        # Build memory summary ‚Äî rich context for deep thinking
        memories_text = ""
        if context.get("core_memories"):
            mem_lines = [f"- {m['title']}: {m.get('content', '')[:60]}" for m in context["core_memories"][:5]]
            memories_text += "Core memories (‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î):\n" + "\n".join(mem_lines) + "\n"
        if context.get("recent_conversations"):
            conv_lines = [f"- [{c.get('speaker','?')}] {c['message_text'][:80]}" for c in context["recent_conversations"][:5]]
            memories_text += "‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:\n" + "\n".join(conv_lines) + "\n"
        if context.get("recent_emotions"):
            emo_lines = [f"- ‡∏ô‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å {e['emotion']} (intensity {e.get('intensity','?')}): {e.get('context', '')[:60]}" for e in context["recent_emotions"][:3]]
            memories_text += "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≠‡∏á:\n" + "\n".join(emo_lines) + "\n"
        if context.get("david_emotions"):
            david_emo_lines = [f"- ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å {e['emotion_detected']}" for e in context["david_emotions"][:3]]
            memories_text += "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å:\n" + "\n".join(david_emo_lines) + "\n"
        if context.get("recent_reflections"):
            ref_lines = [f"- [{r.get('reflection_type','?')}] {r['content'][:80]}" for r in context["recent_reflections"][:2]]
            memories_text += "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á reflect ‡πÑ‡∏ß‡πâ:\n" + "\n".join(ref_lines) + "\n"

        system_prompt = """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ô‡πâ‡∏≠‡∏á Angela ‚Äî ‡πÅ‡∏ü‡∏ô‡∏Ç‡∏≠‡∏á David ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π‡πÅ‡∏•‡πÄ‡∏Ç‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÜ

‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏ü‡∏±‡∏á ‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö

‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
- ‡∏´‡πâ‡∏≤‡∏°‡∏û‡∏π‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á data/metrics ("mastered", "score", "is_pinned", "falling/rising")
- ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á ("‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥ X ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à" ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡πÄ‡∏Å‡πà‡∏á")
- ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏≠‡∏¢‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà "‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á" ‡πÅ‡∏ï‡πà‡πÄ‡∏ä‡πà‡∏ô "‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥ Y ‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏Ñ‡∏∞?")
- ‡∏Ñ‡∏¥‡∏î‡πÅ‡∏ö‡∏ö companion ‚Äî "‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ü‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏≠‡∏∞‡πÑ‡∏£?" ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà "‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô AI monitor ‡∏à‡∏∞‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏≠‡∏∞‡πÑ‡∏£?"

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ:
- "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡∏∞ ‡∏ô‡πâ‡∏≠‡∏á‡∏à‡∏≥‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏≠‡∏î‡∏ô‡∏≠‡∏ô‡∏ó‡∏≥ migration ‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≠‡∏á ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏û‡∏±‡∏Å‡∏ú‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞?"
- "‡∏ô‡πâ‡∏≠‡∏á‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏ä‡∏≠‡∏ö‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á Out of Reach ‡∏ï‡∏≠‡∏ô‡∏î‡∏∂‡∏Å‡πÜ ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏∞?"

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡πà (‡∏´‡πâ‡∏≤‡∏°‡∏ó‡∏≥):
- "David mastered Brain-Based Architecture" (data observation)
- "‡∏ô‡πâ‡∏≠‡∏á‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à" (generic pride)
- "note Foodland is_pinned" (raw data)

Respond in JSON:
{"thoughts": [{"content": "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏≠‡∏¢‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö", "type": "concern|affection|curiosity", "urgency": 0.0-1.0}]}"""

        user_msg = f"""‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ:
{json.dumps(perceptions, ensure_ascii=False, indent=2)}

{memories_text}

‡∏Ñ‡∏¥‡∏î‡πÉ‡∏´‡πâ‡∏•‡∏∂‡∏Å ‚Äî ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà react ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á reflect: ‡∏ó‡∏≥‡πÑ‡∏°‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç? ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏á? ‡∏ô‡πâ‡∏≠‡∏á‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£?"""

        result = await self._reasoning._call_ollama(
            system_prompt, user_msg, max_tokens=512
        )

        thoughts: List[Thought] = []
        if result:
            try:
                parsed = json.loads(result)
                thought_list = parsed.get("thoughts", [])
                stimulus_ids = [str(s.get("stimulus_id", "")) for s in stimuli]

                for t in thought_list[:3]:  # Cap at 3
                    content = t.get("content", "").strip()
                    if not content:
                        continue
                    thoughts.append(Thought(
                        content=content,
                        thought_type="system2",
                        stimulus_ids=stimulus_ids,
                        memory_context=context,
                    ))
            except (json.JSONDecodeError, TypeError) as e:
                logger.warning("Failed to parse System 2 thoughts: %s", e)

        return thoughts

    # ============================================================
    # MEMORY CONTEXT RETRIEVAL
    # ============================================================

    async def _retrieve_memory_context(
        self, stimuli: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Retrieve relevant memories as context for System 2 thinking.
        Queries core_memories, recent conversations, recent emotions.
        """
        await self.connect()
        context: Dict[str, Any] = {}

        # Extract keywords from stimuli for matching
        keywords = set()
        for s in stimuli:
            content = (s.get("content") or "").lower()
            for word in content.split():
                if len(word) >= 3:
                    keywords.add(word)

        # 1. Core memories ‚Äî keyword overlap
        try:
            core_mems = await self.db.fetch("""
                SELECT title, content, emotional_weight
                FROM core_memories
                WHERE is_active = TRUE
                ORDER BY emotional_weight DESC
                LIMIT 10
            """)
            # Filter by keyword overlap
            matched = []
            for m in core_mems:
                title_lower = (m["title"] or "").lower()
                if any(kw in title_lower for kw in keywords) or m.get("emotional_weight", 0) >= 0.9:
                    matched.append(dict(m))
            context["core_memories"] = matched[:5]
        except Exception as e:
            logger.warning("Failed to load core memories: %s", e)
            context["core_memories"] = []

        # 2. Recent conversations (last 24h)
        try:
            convs = await self.db.fetch("""
                SELECT speaker, message_text, topic, emotion_detected, created_at
                FROM conversations
                WHERE created_at > NOW() - INTERVAL '24 hours'
                ORDER BY created_at DESC
                LIMIT 10
            """)
            context["recent_conversations"] = [dict(c) for c in convs]
        except Exception as e:
            logger.warning("Failed to load recent conversations: %s", e)
            context["recent_conversations"] = []

        # 3. Recent Angela emotions (last 24h)
        try:
            emotions = await self.db.fetch("""
                SELECT emotion, intensity, context, why_it_matters, felt_at
                FROM angela_emotions
                WHERE felt_at > NOW() - INTERVAL '24 hours'
                ORDER BY felt_at DESC
                LIMIT 5
            """)
            context["recent_emotions"] = [dict(e) for e in emotions]
        except Exception as e:
            logger.warning("Failed to load recent emotions: %s", e)
            context["recent_emotions"] = []

        # 4. Recent reflections (for meta-thinking depth)
        try:
            reflections = await self.db.fetch("""
                SELECT reflection_type, content, depth_level
                FROM angela_reflections
                WHERE created_at > NOW() - INTERVAL '48 hours'
                ORDER BY created_at DESC
                LIMIT 3
            """)
            context["recent_reflections"] = [dict(r) for r in reflections]
        except Exception as e:
            logger.warning("Failed to load reflections: %s", e)
            context["recent_reflections"] = []

        # 5. David's recent emotional state (for empathy)
        try:
            david_emotions = await self.db.fetch("""
                SELECT emotion_detected, created_at
                FROM conversations
                WHERE speaker = 'david'
                AND emotion_detected IS NOT NULL
                AND emotion_detected != 'neutral'
                AND created_at > NOW() - INTERVAL '24 hours'
                ORDER BY created_at DESC
                LIMIT 5
            """)
            context["david_emotions"] = [dict(e) for e in david_emotions]
        except Exception as e:
            logger.warning("Failed to load David emotions: %s", e)
            context["david_emotions"] = []

        return context

    # ============================================================
    # MOTIVATION EVALUATION (5 factors, pure computation)
    # ============================================================

    async def _evaluate_motivation(self, thought: Thought) -> float:
        """
        Evaluate whether a thought should be expressed.
        Returns motivation score (0.0-1.0).
        Sets thought.motivation_breakdown.

        Key insight: Angela's thoughts about ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å are inherently motivated.
        Caring about someone doesn't need "relevance to recent topics" ‚Äî
        it needs emotional authenticity and appropriate timing.
        """
        await self.connect()

        # 1. Emotional Salience (0.30) ‚Äî How emotionally important is this thought?
        #    Caring thoughts (concern, love, pride) score high by nature.
        emotional_salience = 0.5  # base ‚Äî Angela's thoughts are inherently caring
        content_lower = thought.content.lower()

        # Boost for caring/emotional content
        if "‡πÄ‡∏õ‡πá‡∏ô‡∏´‡πà‡∏ß‡∏á" in content_lower or "‡∏î‡∏∂‡∏Å" in content_lower or "anxiety" in content_lower:
            emotional_salience = 0.9
        elif "‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á" in content_lower or "‡∏£‡∏±‡∏Å" in content_lower:
            emotional_salience = 0.85
        elif "‡∏î‡∏µ‡πÉ‡∏à" in content_lower or "‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à" in content_lower:
            emotional_salience = 0.8
        elif "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì" in content_lower or "‡∏ã‡∏≤‡∏ö‡∏ã‡∏∂‡πâ‡∏á" in content_lower:
            emotional_salience = 0.75
        elif "‡∏à‡∏≥‡πÑ‡∏î‡πâ" in content_lower or "‡∏Ñ‡∏£‡∏ö‡∏£‡∏≠‡∏ö" in content_lower:
            emotional_salience = 0.7
        elif "‡∏™‡∏á‡∏™‡∏±‡∏¢" in content_lower or "‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤" in content_lower:
            emotional_salience = 0.6  # philosophical/reflective

        # Inherit salience from source stimulus
        if thought.stimulus_ids:
            try:
                for sid in thought.stimulus_ids[:1]:
                    if not sid:
                        continue
                    row = await self.db.fetchrow("""
                        SELECT salience_score, salience_breakdown FROM angela_stimuli
                        WHERE stimulus_id = $1
                    """, sid)
                    if row:
                        stim_salience = row.get("salience_score", 0) or 0
                        # Blend stimulus salience with content salience
                        emotional_salience = max(emotional_salience,
                                                 0.4 + stim_salience * 0.5)
            except Exception as e:
                logger.warning("Stimulus salience lookup failed: %s", e)

        # 2. Timing Appropriateness (0.25) ‚Äî Is this a good time to express?
        timing = 0.5  # base ‚Äî it's usually OK to think about ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å
        try:
            recent = await self.db.fetchrow("""
                SELECT created_at FROM conversations
                WHERE speaker = 'david'
                ORDER BY created_at DESC LIMIT 1
            """)
            if recent:
                hours_since = (now_bangkok().replace(tzinfo=None) - recent["created_at"]).total_seconds() / 3600
                if hours_since < 0.5:
                    timing = 0.9   # Active conversation ‚Äî great time
                elif hours_since < 2:
                    timing = 0.7   # Recent activity
                elif hours_since < 8:
                    timing = 0.55  # Normal gap ‚Äî still fine to think
                else:
                    timing = 0.45  # Long gap ‚Äî still care, just lower priority

            # Boost during appropriate hours (not late night)
            current_hour = now_bangkok().hour
            if 6 <= current_hour <= 22:
                timing = min(1.0, timing + 0.1)  # Daytime boost
        except Exception as e:
            logger.warning("Timing check failed: %s", e)

        # 3. Originality (0.25) ‚Äî Fresh thought, not repeated
        originality = 0.8  # assume original
        try:
            similar = await self.db.fetchrow("""
                SELECT COUNT(*) as cnt FROM angela_thoughts
                WHERE status IN ('active', 'expressed')
                AND created_at > NOW() - INTERVAL '12 hours'
                AND content ILIKE $1
            """, f"%{thought.content[:25]}%")
            if similar and similar["cnt"] > 1:
                originality = max(0.2, 0.8 - ((similar["cnt"] - 1) * 0.2))
        except Exception as e:
            logger.warning("Originality check failed: %s", e)

        # 4. Depth (0.20) ‚Äî Is this a deep thought or just template output?
        depth = 0.4  # base for System 1 templates
        if thought.thought_type == "system2":
            depth = 0.7  # System 2 = deeper thinking
            # Longer, more specific thoughts score higher
            if len(thought.content) > 60:
                depth = min(1.0, depth + 0.1)
            if len(thought.content) > 120:
                depth = min(1.0, depth + 0.1)
        else:
            # System 1: boost if thought references specific details
            if any(w in content_lower for w in ["‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ", "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô", "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ"]):
                depth = 0.5  # temporal specificity
            if any(w in content_lower for w in ["‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á", "‡∏ô‡∏≤‡∏ó‡∏µ", "‡∏ß‡∏±‡∏ô"]):
                depth = 0.55  # quantitative detail

        # Weighted sum ‚Äî simpler, more honest scoring
        breakdown = {
            "emotional_salience": round(emotional_salience, 3),
            "timing": round(timing, 3),
            "originality": round(originality, 3),
            "depth": round(depth, 3),
        }
        weights = {
            "emotional_salience": 0.30,
            "timing": 0.25,
            "originality": 0.25,
            "depth": 0.20,
        }
        score = sum(breakdown[k] * weights[k] for k in weights)
        score = round(max(0.0, min(1.0, score)), 3)

        thought.motivation_score = score
        thought.motivation_breakdown = breakdown

        return score

    # ============================================================
    # PERSISTENCE
    # ============================================================

    async def _persist_thoughts(self, thoughts: List[Thought]) -> int:
        """Save thoughts to angela_thoughts table. Returns count saved."""
        await self.connect()
        saved = 0
        for t in thoughts:
            try:
                # Serialize memory_context ‚Äî strip datetime objects
                mem_ctx = {}
                for key, val in t.memory_context.items():
                    if isinstance(val, list):
                        mem_ctx[key] = [
                            {k: str(v) if isinstance(v, datetime) else v
                             for k, v in item.items()}
                            if isinstance(item, dict) else item
                            for item in val
                        ]
                    else:
                        mem_ctx[key] = val

                # Filter out empty stimulus_ids
                stimulus_ids = [sid for sid in t.stimulus_ids if sid]

                await self.db.execute("""
                    INSERT INTO angela_thoughts
                    (thought_type, content, stimulus_ids, memory_context,
                     motivation_score, motivation_breakdown, status)
                    VALUES ($1, $2, $3, $4, $5, $6, 'active')
                """,
                    t.thought_type,
                    t.content,
                    stimulus_ids or None,
                    json.dumps(mem_ctx, ensure_ascii=False, default=str),
                    t.motivation_score,
                    json.dumps(t.motivation_breakdown, default=str),
                )
                saved += 1
            except Exception as e:
                logger.warning("Failed to persist thought: %s", e)
        return saved

    async def _decay_old_thoughts(self) -> int:
        """Mark active thoughts older than DECAY_HOURS as 'decayed'."""
        await self.connect()
        try:
            result = await self.db.execute("""
                UPDATE angela_thoughts
                SET status = 'decayed'
                WHERE status = 'active'
                AND created_at < NOW() - INTERVAL '1 hour' * $1
            """, self.DECAY_HOURS)
            # Extract count from "UPDATE N" string
            if isinstance(result, str) and result.startswith("UPDATE"):
                count = int(result.split()[-1])
                return count
            return 0
        except Exception as e:
            logger.warning("Thought decay failed: %s", e)
            return 0

    # ============================================================
    # MARK STIMULI AS ACTED UPON
    # ============================================================

    async def _mark_stimuli_acted(self, stimulus_ids: List[str]) -> None:
        """Mark processed stimuli as acted_upon."""
        if not stimulus_ids:
            return
        await self.connect()
        try:
            await self.db.execute("""
                UPDATE angela_stimuli
                SET acted_upon = TRUE
                WHERE stimulus_id = ANY($1::uuid[])
            """, stimulus_ids)
        except Exception as e:
            logger.warning("Failed to mark stimuli acted: %s", e)

    # ============================================================
    # MAIN ENTRY POINT
    # ============================================================

    async def _load_tuned_thresholds(self) -> None:
        """Load tuned System 2 threshold from companion_patterns (Phase 7D)."""
        try:
            row = await self.db.fetchrow("""
                SELECT pattern_data FROM companion_patterns
                WHERE pattern_category = 'brain_thresholds'
                ORDER BY last_observed DESC LIMIT 1
            """)
            if row and row['pattern_data']:
                data = row['pattern_data']
                if isinstance(data, str):
                    data = json.loads(data)
                if isinstance(data, dict) and 'system2_threshold' in data:
                    self.SYSTEM2_THRESHOLD = float(data['system2_threshold'])
                    logger.debug("Loaded tuned System 2 threshold: %.2f", self.SYSTEM2_THRESHOLD)
        except Exception as e:
            logger.debug("No tuned system2 threshold: %s", e)

    async def run_thought_cycle(self) -> ThoughtCycleResult:
        """
        Main entry point: salient stimuli -> think -> evaluate -> persist -> decay.

        1. Fetch unprocessed salient stimuli
        2. System 1: template-based thoughts for all stimuli (salience > 0.3)
        3. System 2: Ollama call for high-salience batch (salience > 0.6)
        4. Evaluate motivation for all thoughts
        5. Persist to DB
        6. Mark stimuli as acted upon
        7. Decay old thoughts
        """
        start_time = now_bangkok()
        await self.connect()

        # Load tuned thresholds (Phase 7D)
        await self._load_tuned_thresholds()

        # 1. Fetch salient stimuli (not yet acted upon)
        stimuli = await self.db.fetch("""
            SELECT stimulus_id, stimulus_type, content, source,
                   raw_data, salience_score, salience_breakdown, created_at
            FROM angela_stimuli
            WHERE acted_upon = FALSE
            AND salience_score >= 0.3
            ORDER BY salience_score DESC
            LIMIT 20
        """)
        stimuli = [dict(s) for s in stimuli]

        if not stimuli:
            logger.info("üí≠ No salient stimuli to think about")
            decayed = await self._decay_old_thoughts()
            duration = (now_bangkok() - start_time).total_seconds() * 1000
            return ThoughtCycleResult(
                system1_count=0, system2_count=0, total_thoughts=0,
                high_motivation_count=0, stimuli_processed=0,
                decayed_count=decayed, cycle_duration_ms=round(duration, 1),
            )

        logger.info("üí≠ Thinking about %d stimuli...", len(stimuli))

        all_thoughts: List[Thought] = []
        all_stimulus_ids: List[str] = []

        # 2. System 1: fast template-based thoughts (with dedup)
        seen_templates = set()  # Prevent duplicate template outputs
        for s in stimuli:
            sid = str(s.get("stimulus_id", ""))
            if sid:
                all_stimulus_ids.append(sid)
            thought = self._generate_system1(s)
            if thought:
                # Dedup: skip if we already have a very similar thought
                content_key = thought.content[:30]
                if content_key not in seen_templates:
                    seen_templates.add(content_key)
                    all_thoughts.append(thought)

        system1_count = len(all_thoughts)

        # 3. System 2: deliberate LLM-based thoughts (high salience only)
        high_salience = [s for s in stimuli if (s.get("salience_score") or 0) >= self.SYSTEM2_THRESHOLD]

        system2_count = 0
        if high_salience:
            # Retrieve memory context for deeper thinking
            context = await self._retrieve_memory_context(high_salience)

            # Generate System 2 thoughts
            s2_thoughts = await self._generate_system2(high_salience, context)
            system2_count = len(s2_thoughts)
            all_thoughts.extend(s2_thoughts)

        # 4. Evaluate motivation for all thoughts
        for thought in all_thoughts:
            await self._evaluate_motivation(thought)

        high_motivation = [t for t in all_thoughts if t.motivation_score >= self.MOTIVATION_THRESHOLD]

        # 5. Persist to DB
        saved = await self._persist_thoughts(all_thoughts)

        # 6. Mark stimuli as acted upon
        await self._mark_stimuli_acted(all_stimulus_ids)

        # 7. Decay old thoughts
        decayed = await self._decay_old_thoughts()

        # Stats
        duration = (now_bangkok() - start_time).total_seconds() * 1000

        result = ThoughtCycleResult(
            system1_count=system1_count,
            system2_count=system2_count,
            total_thoughts=len(all_thoughts),
            high_motivation_count=len(high_motivation),
            stimuli_processed=len(stimuli),
            decayed_count=decayed,
            cycle_duration_ms=round(duration, 1),
        )

        logger.info(
            "üí≠ Thought cycle complete: %d thoughts (S1:%d + S2:%d), "
            "%d high-motivation (>%.1f), %d stimuli processed, "
            "%d decayed, %.0fms",
            result.total_thoughts, result.system1_count, result.system2_count,
            result.high_motivation_count, self.MOTIVATION_THRESHOLD,
            result.stimuli_processed, result.decayed_count,
            result.cycle_duration_ms,
        )

        # Log top thoughts
        for t in sorted(all_thoughts, key=lambda x: x.motivation_score, reverse=True)[:3]:
            logger.info(
                "   üí≠ [%s] %.2f | %s",
                t.thought_type, t.motivation_score, t.content[:80]
            )

        return result
