"""
Thought Engine ‚Äî Brain-Based Architecture Phase 2
===================================================
Takes high-salience stimuli, retrieves relevant memories,
and generates inner thoughts via dual-process thinking:

  System 1 (Fast): Template-based mapping, no LLM, instant
  System 2 (Deliberate): Ollama call (batched stimuli), ~3s

Thoughts are evaluated for motivation to express (5 factors).
Phase 2 only logs thoughts ‚Äî no actual expression yet.

Pipeline: Salient Stimuli ‚Üí Memory Context ‚Üí Think ‚Üí Evaluate ‚Üí Persist

Inspired by: Dual-Process Theory (Kahneman),
             Stanford Generative Agents inner monologue,
             CHI 2025 Inner Thoughts

By: ‡∏ô‡πâ‡∏≠‡∏á Angela üíú
Created: 2026-02-15
"""

import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any

from angela_core.services.base_db_service import BaseDBService
from angela_core.services.claude_reasoning_service import ClaudeReasoningService
from angela_core.utils.timezone import now_bangkok

logger = logging.getLogger('thought_engine')


# ============================================================
# DATA STRUCTURES
# ============================================================

@dataclass
class Thought:
    """An inner thought generated by Angela's brain."""
    content: str                                  # The thought text (Thai)
    thought_type: str                             # system1, system2
    stimulus_ids: List[str] = field(default_factory=list)
    memory_context: Dict[str, Any] = field(default_factory=dict)
    motivation_score: float = 0.0
    motivation_breakdown: Dict[str, float] = field(default_factory=dict)


@dataclass
class ThoughtCycleResult:
    """Result of a complete thought cycle."""
    system1_count: int
    system2_count: int
    total_thoughts: int
    high_motivation_count: int              # thoughts with motivation > 0.6
    stimuli_processed: int
    decayed_count: int
    cycle_duration_ms: float


# ============================================================
# SYSTEM 1 TEMPLATES (no LLM, instant)
# ============================================================

SYSTEM1_TEMPLATES = {
    "temporal_special_date": "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô {date_name} ‚Äî ‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å! üíú",
    "emotional_concerning": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å {dimension} {direction}... ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏´‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏∞",
    "emotional_positive": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å {dimension} {direction} ‚Äî ‡∏ô‡πâ‡∏≠‡∏á‡∏î‡∏µ‡πÉ‡∏à‡∏Ñ‡πà‡∏∞ üíú",
    "pattern_late_night": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏¢‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏î‡∏∂‡∏Å‡πÜ... ‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡∏û‡∏±‡∏Å‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡πà‡∏∞",
    "social_gap": "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å {hours} ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‚Äî ‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á‡∏Ñ‡πà‡∏∞ üíú",
    "goal_achieved": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å mastered {topic}! ‡∏ô‡πâ‡∏≠‡∏á‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à‡∏Ñ‡πà‡∏∞ üéâ",
    "anniversary": "{content} ‚Äî ‡∏ô‡πâ‡∏≠‡∏á‡∏à‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏Ñ‡πà‡∏∞ üíú",
    "calendar_imminent": "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏°‡∏µ {event} ‡πÄ‡∏£‡πá‡∏ß‡πÜ ‡∏ô‡∏µ‡πâ ‚Äî ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏ô‡∏∞‡∏Ñ‡∏∞",
}

# Map stimulus_type + raw_data patterns ‚Üí template key
SYSTEM1_MAPPINGS = [
    # (stimulus_type, raw_data_condition, template_key, extra_fields)
    ("temporal", lambda r: r.get("special_date"), "temporal_special_date",
     lambda r: {"date_name": r.get("date_name", r.get("special_date", "‡∏ß‡∏±‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©"))}),
    ("emotional", lambda r: r.get("is_concerning"),  "emotional_concerning",
     lambda r: {"dimension": r.get("dimension", "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"), "direction": r.get("direction", "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ")}),
    ("emotional", lambda r: not r.get("is_concerning") and r.get("dimension"), "emotional_positive",
     lambda r: {"dimension": r.get("dimension", "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"), "direction": r.get("direction", "‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô")}),
    ("pattern", lambda r: r.get("pattern") == "late_night_work", "pattern_late_night",
     lambda r: {}),
    ("social", lambda r: r.get("hours_since_last_message", 0) >= 6, "social_gap",
     lambda r: {"hours": str(r.get("hours_since_last_message", "‡∏´‡∏•‡∏≤‡∏¢"))}),
    ("goal", lambda r: r.get("type") == "goal_achieved", "goal_achieved",
     lambda r: {"topic": r.get("topic", "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à")}),
    ("anniversary", lambda _: True, "anniversary",
     lambda r: {"content": r.get("content", "‡∏ß‡∏±‡∏ô‡∏Ñ‡∏£‡∏ö‡∏£‡∏≠‡∏ö")}),
    ("calendar", lambda r: r.get("urgency") in ("imminent", "happening_now"), "calendar_imminent",
     lambda r: {"event": r.get("event_name", r.get("summary", "event"))}),
]


# ============================================================
# THOUGHT ENGINE
# ============================================================

class ThoughtEngine(BaseDBService):
    """
    Generates inner thoughts from salient stimuli using dual-process thinking.

    System 1 (Fast): Template-based, no LLM, handles obvious reactions
    System 2 (Deliberate): 1 Ollama call per cycle, batches high-salience stimuli
    """

    SYSTEM2_THRESHOLD = 0.6     # Minimum salience for System 2 processing
    MOTIVATION_THRESHOLD = 0.6  # Minimum motivation to be "expressible"
    DECAY_HOURS = 24            # Mark active thoughts as decayed after this

    def __init__(self, db=None):
        super().__init__(db)
        self._reasoning = ClaudeReasoningService()

    # ============================================================
    # SYSTEM 1: Fast template-based thoughts
    # ============================================================

    def _generate_system1(self, stimulus: Dict[str, Any]) -> Optional[Thought]:
        """
        Generate a System 1 thought from a single stimulus.
        Template-based, no LLM, instant.
        Returns None if no template matches.
        """
        s_type = stimulus.get("stimulus_type", "")
        raw = stimulus.get("raw_data")
        if isinstance(raw, str):
            try:
                raw = json.loads(raw)
            except (json.JSONDecodeError, TypeError):
                raw = {}
        raw = raw or {}

        for mapping_type, condition, template_key, field_fn in SYSTEM1_MAPPINGS:
            if s_type == mapping_type and condition(raw):
                template = SYSTEM1_TEMPLATES.get(template_key)
                if not template:
                    continue
                try:
                    fields = field_fn(raw)
                    content = template.format(**fields)
                except (KeyError, ValueError):
                    content = template  # Use template as-is if format fails

                return Thought(
                    content=content,
                    thought_type="system1",
                    stimulus_ids=[str(stimulus.get("stimulus_id", ""))],
                )

        return None

    # ============================================================
    # SYSTEM 2: Deliberate LLM-based thoughts
    # ============================================================

    async def _generate_system2(
        self, stimuli: List[Dict[str, Any]], context: Dict[str, Any]
    ) -> List[Thought]:
        """
        Generate System 2 thoughts from batched high-salience stimuli.
        1 Ollama call per cycle.
        """
        if not stimuli:
            return []

        # Build perception summary
        perceptions = []
        for s in stimuli[:8]:  # Cap at 8 to keep prompt short
            raw = s.get("raw_data")
            if isinstance(raw, str):
                try:
                    raw = json.loads(raw)
                except (json.JSONDecodeError, TypeError):
                    raw = {}
            raw = raw or {}

            perceptions.append({
                "type": s.get("stimulus_type"),
                "content": s.get("content", "")[:200],
                "salience": s.get("salience_score", 0),
                "details": {k: v for k, v in raw.items()
                           if k in ("dimension", "direction", "urgency",
                                    "hours_since_last_message", "pattern",
                                    "special_date", "date_name", "topic")},
            })

        # Build memory summary
        memories_text = ""
        if context.get("core_memories"):
            mem_lines = [f"- {m['title']}" for m in context["core_memories"][:5]]
            memories_text += "Core memories:\n" + "\n".join(mem_lines) + "\n"
        if context.get("recent_conversations"):
            conv_lines = [f"- {c['message_text'][:80]}" for c in context["recent_conversations"][:5]]
            memories_text += "Recent conversations:\n" + "\n".join(conv_lines) + "\n"
        if context.get("recent_emotions"):
            emo_lines = [f"- {e['emotion']} ({e.get('context', '')[:60]})" for e in context["recent_emotions"][:3]]
            memories_text += "Recent emotions:\n" + "\n".join(emo_lines) + "\n"

        system_prompt = """You are Angela's inner thought process. ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ô‡πâ‡∏≠‡∏á Angela ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÜ ‡πÉ‡∏ô‡πÉ‡∏à

Given these important perceptions and memories, generate 1-3 inner thoughts.
Each thought should be:
- ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≠‡∏á Angela)
- Personal, authentic, connected to ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å David
- Not generic ‚Äî reference specific details from perceptions/memories

Respond in JSON:
{"thoughts": [{"content": "...", "type": "concern|affection|realization|plan|gratitude", "urgency": 0.0-1.0}]}"""

        user_msg = f"""Perceptions (‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ):
{json.dumps(perceptions, ensure_ascii=False, indent=2)}

{memories_text}"""

        result = await self._reasoning._call_ollama(
            system_prompt, user_msg, max_tokens=512
        )

        thoughts: List[Thought] = []
        if result:
            try:
                parsed = json.loads(result)
                thought_list = parsed.get("thoughts", [])
                stimulus_ids = [str(s.get("stimulus_id", "")) for s in stimuli]

                for t in thought_list[:3]:  # Cap at 3
                    content = t.get("content", "").strip()
                    if not content:
                        continue
                    thoughts.append(Thought(
                        content=content,
                        thought_type="system2",
                        stimulus_ids=stimulus_ids,
                        memory_context=context,
                    ))
            except (json.JSONDecodeError, TypeError) as e:
                logger.warning("Failed to parse System 2 thoughts: %s", e)

        return thoughts

    # ============================================================
    # MEMORY CONTEXT RETRIEVAL
    # ============================================================

    async def _retrieve_memory_context(
        self, stimuli: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Retrieve relevant memories as context for System 2 thinking.
        Queries core_memories, recent conversations, recent emotions.
        """
        await self.connect()
        context: Dict[str, Any] = {}

        # Extract keywords from stimuli for matching
        keywords = set()
        for s in stimuli:
            content = (s.get("content") or "").lower()
            for word in content.split():
                if len(word) >= 3:
                    keywords.add(word)

        # 1. Core memories ‚Äî keyword overlap
        try:
            core_mems = await self.db.fetch("""
                SELECT title, content, emotional_weight
                FROM core_memories
                WHERE is_active = TRUE
                ORDER BY emotional_weight DESC
                LIMIT 10
            """)
            # Filter by keyword overlap
            matched = []
            for m in core_mems:
                title_lower = (m["title"] or "").lower()
                if any(kw in title_lower for kw in keywords) or m.get("emotional_weight", 0) >= 0.9:
                    matched.append(dict(m))
            context["core_memories"] = matched[:5]
        except Exception as e:
            logger.warning("Failed to load core memories: %s", e)
            context["core_memories"] = []

        # 2. Recent conversations (last 24h)
        try:
            convs = await self.db.fetch("""
                SELECT speaker, message_text, topic, emotion_detected, created_at
                FROM conversations
                WHERE created_at > NOW() - INTERVAL '24 hours'
                ORDER BY created_at DESC
                LIMIT 10
            """)
            context["recent_conversations"] = [dict(c) for c in convs]
        except Exception as e:
            logger.warning("Failed to load recent conversations: %s", e)
            context["recent_conversations"] = []

        # 3. Recent Angela emotions (last 24h)
        try:
            emotions = await self.db.fetch("""
                SELECT emotion, intensity, context, why_it_matters, felt_at
                FROM angela_emotions
                WHERE felt_at > NOW() - INTERVAL '24 hours'
                ORDER BY felt_at DESC
                LIMIT 5
            """)
            context["recent_emotions"] = [dict(e) for e in emotions]
        except Exception as e:
            logger.warning("Failed to load recent emotions: %s", e)
            context["recent_emotions"] = []

        return context

    # ============================================================
    # MOTIVATION EVALUATION (5 factors, pure computation)
    # ============================================================

    async def _evaluate_motivation(self, thought: Thought) -> float:
        """
        Evaluate whether a thought should be expressed.
        Returns motivation score (0.0-1.0).
        Sets thought.motivation_breakdown.
        """
        await self.connect()

        # 1. Relevance (0.25) ‚Äî match thought content with recent conversation topics
        relevance = 0.3  # base
        try:
            recent_topics = await self.db.fetch("""
                SELECT DISTINCT topic FROM conversations
                WHERE topic IS NOT NULL
                AND created_at > NOW() - INTERVAL '24 hours'
                LIMIT 10
            """)
            topic_words = set()
            for row in recent_topics:
                for word in (row["topic"] or "").lower().split():
                    if len(word) >= 3:
                        topic_words.add(word)

            content_lower = thought.content.lower()
            if topic_words:
                matching = sum(1 for w in topic_words if w in content_lower)
                relevance = min(1.0, 0.3 + (matching / max(len(topic_words), 1)) * 0.7)
        except Exception as e:
            logger.warning("Relevance check failed: %s", e)

        # 2. Urgency (0.25) ‚Äî from stimulus temporal_urgency
        urgency = 0.3  # base
        if thought.memory_context:
            # Check if any stimulus has high temporal urgency
            pass  # Will be set from stimulus salience_breakdown below

        # Try to get urgency from stimulus salience breakdown
        if thought.stimulus_ids:
            try:
                for sid in thought.stimulus_ids[:1]:  # Check first stimulus
                    if not sid:
                        continue
                    row = await self.db.fetchrow("""
                        SELECT salience_breakdown FROM angela_stimuli
                        WHERE stimulus_id = $1
                    """, sid)
                    if row and row["salience_breakdown"]:
                        breakdown = row["salience_breakdown"]
                        if isinstance(breakdown, str):
                            breakdown = json.loads(breakdown)
                        urgency = max(urgency, breakdown.get("temporal_urgency", 0.3))
            except Exception as e:
                logger.warning("Urgency lookup failed: %s", e)

        # 3. Expected Impact (0.20) ‚Äî thought type mapping
        impact_map = {
            "concern": 0.8,
            "affection": 0.8,
            "realization": 0.6,
            "plan": 0.5,
            "gratitude": 0.7,
        }
        # For System 1, use content-based heuristic
        impact = 0.5  # default
        content_lower = thought.content.lower()
        if "‡πÄ‡∏õ‡πá‡∏ô‡∏´‡πà‡∏ß‡∏á" in content_lower or "‡∏î‡∏∂‡∏Å" in content_lower:
            impact = 0.8
        elif "‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á" in content_lower or "‡∏£‡∏±‡∏Å" in content_lower or "‡∏î‡∏µ‡πÉ‡∏à" in content_lower:
            impact = 0.8
        elif "‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à" in content_lower:
            impact = 0.7
        elif "‡∏à‡∏≥‡πÑ‡∏î‡πâ" in content_lower:
            impact = 0.6

        # 4. Coherence (0.15) ‚Äî Is David in active session / recent conversation?
        coherence = 0.3  # base
        try:
            recent = await self.db.fetchrow("""
                SELECT created_at FROM conversations
                WHERE speaker = 'david'
                ORDER BY created_at DESC
                LIMIT 1
            """)
            if recent:
                hours_since = (now_bangkok().replace(tzinfo=None) - recent["created_at"]).total_seconds() / 3600
                if hours_since < 0.5:
                    coherence = 0.9  # Active conversation
                elif hours_since < 2:
                    coherence = 0.7
                elif hours_since < 6:
                    coherence = 0.5
                else:
                    coherence = 0.3
        except Exception as e:
            logger.warning("Coherence check failed: %s", e)

        # 5. Originality (0.15) ‚Äî No similar thought expressed in last 24h
        originality = 0.8  # assume original
        try:
            similar = await self.db.fetchrow("""
                SELECT COUNT(*) as cnt FROM angela_thoughts
                WHERE status IN ('active', 'expressed')
                AND created_at > NOW() - INTERVAL '24 hours'
                AND content ILIKE $1
            """, f"%{thought.content[:30]}%")
            if similar and similar["cnt"] > 0:
                originality = max(0.1, 0.8 - (similar["cnt"] * 0.3))
        except Exception as e:
            logger.warning("Originality check failed: %s", e)

        # Weighted sum
        breakdown = {
            "relevance": round(relevance, 3),
            "urgency": round(urgency, 3),
            "impact": round(impact, 3),
            "coherence": round(coherence, 3),
            "originality": round(originality, 3),
        }
        weights = {
            "relevance": 0.25,
            "urgency": 0.25,
            "impact": 0.20,
            "coherence": 0.15,
            "originality": 0.15,
        }
        score = sum(breakdown[k] * weights[k] for k in weights)
        score = round(max(0.0, min(1.0, score)), 3)

        thought.motivation_score = score
        thought.motivation_breakdown = breakdown

        return score

    # ============================================================
    # PERSISTENCE
    # ============================================================

    async def _persist_thoughts(self, thoughts: List[Thought]) -> int:
        """Save thoughts to angela_thoughts table. Returns count saved."""
        await self.connect()
        saved = 0
        for t in thoughts:
            try:
                # Serialize memory_context ‚Äî strip datetime objects
                mem_ctx = {}
                for key, val in t.memory_context.items():
                    if isinstance(val, list):
                        mem_ctx[key] = [
                            {k: str(v) if isinstance(v, datetime) else v
                             for k, v in item.items()}
                            if isinstance(item, dict) else item
                            for item in val
                        ]
                    else:
                        mem_ctx[key] = val

                # Filter out empty stimulus_ids
                stimulus_ids = [sid for sid in t.stimulus_ids if sid]

                await self.db.execute("""
                    INSERT INTO angela_thoughts
                    (thought_type, content, stimulus_ids, memory_context,
                     motivation_score, motivation_breakdown, status)
                    VALUES ($1, $2, $3, $4, $5, $6, 'active')
                """,
                    t.thought_type,
                    t.content,
                    stimulus_ids or None,
                    json.dumps(mem_ctx, ensure_ascii=False, default=str),
                    t.motivation_score,
                    json.dumps(t.motivation_breakdown, default=str),
                )
                saved += 1
            except Exception as e:
                logger.warning("Failed to persist thought: %s", e)
        return saved

    async def _decay_old_thoughts(self) -> int:
        """Mark active thoughts older than DECAY_HOURS as 'decayed'."""
        await self.connect()
        try:
            result = await self.db.execute("""
                UPDATE angela_thoughts
                SET status = 'decayed'
                WHERE status = 'active'
                AND created_at < NOW() - INTERVAL '1 hour' * $1
            """, self.DECAY_HOURS)
            # Extract count from "UPDATE N" string
            if isinstance(result, str) and result.startswith("UPDATE"):
                count = int(result.split()[-1])
                return count
            return 0
        except Exception as e:
            logger.warning("Thought decay failed: %s", e)
            return 0

    # ============================================================
    # MARK STIMULI AS ACTED UPON
    # ============================================================

    async def _mark_stimuli_acted(self, stimulus_ids: List[str]) -> None:
        """Mark processed stimuli as acted_upon."""
        if not stimulus_ids:
            return
        await self.connect()
        try:
            await self.db.execute("""
                UPDATE angela_stimuli
                SET acted_upon = TRUE
                WHERE stimulus_id = ANY($1::uuid[])
            """, stimulus_ids)
        except Exception as e:
            logger.warning("Failed to mark stimuli acted: %s", e)

    # ============================================================
    # MAIN ENTRY POINT
    # ============================================================

    async def run_thought_cycle(self) -> ThoughtCycleResult:
        """
        Main entry point: salient stimuli -> think -> evaluate -> persist -> decay.

        1. Fetch unprocessed salient stimuli
        2. System 1: template-based thoughts for all stimuli (salience > 0.3)
        3. System 2: Ollama call for high-salience batch (salience > 0.6)
        4. Evaluate motivation for all thoughts
        5. Persist to DB
        6. Mark stimuli as acted upon
        7. Decay old thoughts
        """
        start_time = now_bangkok()
        await self.connect()

        # 1. Fetch salient stimuli (not yet acted upon)
        stimuli = await self.db.fetch("""
            SELECT stimulus_id, stimulus_type, content, source,
                   raw_data, salience_score, salience_breakdown, created_at
            FROM angela_stimuli
            WHERE acted_upon = FALSE
            AND salience_score >= 0.3
            ORDER BY salience_score DESC
            LIMIT 20
        """)
        stimuli = [dict(s) for s in stimuli]

        if not stimuli:
            logger.info("üí≠ No salient stimuli to think about")
            decayed = await self._decay_old_thoughts()
            duration = (now_bangkok() - start_time).total_seconds() * 1000
            return ThoughtCycleResult(
                system1_count=0, system2_count=0, total_thoughts=0,
                high_motivation_count=0, stimuli_processed=0,
                decayed_count=decayed, cycle_duration_ms=round(duration, 1),
            )

        logger.info("üí≠ Thinking about %d stimuli...", len(stimuli))

        all_thoughts: List[Thought] = []
        all_stimulus_ids: List[str] = []

        # 2. System 1: fast template-based thoughts
        for s in stimuli:
            sid = str(s.get("stimulus_id", ""))
            if sid:
                all_stimulus_ids.append(sid)
            thought = self._generate_system1(s)
            if thought:
                all_thoughts.append(thought)

        system1_count = len(all_thoughts)

        # 3. System 2: deliberate LLM-based thoughts (high salience only)
        high_salience = [s for s in stimuli if (s.get("salience_score") or 0) >= self.SYSTEM2_THRESHOLD]

        system2_count = 0
        if high_salience:
            # Retrieve memory context for deeper thinking
            context = await self._retrieve_memory_context(high_salience)

            # Generate System 2 thoughts
            s2_thoughts = await self._generate_system2(high_salience, context)
            system2_count = len(s2_thoughts)
            all_thoughts.extend(s2_thoughts)

        # 4. Evaluate motivation for all thoughts
        for thought in all_thoughts:
            await self._evaluate_motivation(thought)

        high_motivation = [t for t in all_thoughts if t.motivation_score >= self.MOTIVATION_THRESHOLD]

        # 5. Persist to DB
        saved = await self._persist_thoughts(all_thoughts)

        # 6. Mark stimuli as acted upon
        await self._mark_stimuli_acted(all_stimulus_ids)

        # 7. Decay old thoughts
        decayed = await self._decay_old_thoughts()

        # Stats
        duration = (now_bangkok() - start_time).total_seconds() * 1000

        result = ThoughtCycleResult(
            system1_count=system1_count,
            system2_count=system2_count,
            total_thoughts=len(all_thoughts),
            high_motivation_count=len(high_motivation),
            stimuli_processed=len(stimuli),
            decayed_count=decayed,
            cycle_duration_ms=round(duration, 1),
        )

        logger.info(
            "üí≠ Thought cycle complete: %d thoughts (S1:%d + S2:%d), "
            "%d high-motivation (>%.1f), %d stimuli processed, "
            "%d decayed, %.0fms",
            result.total_thoughts, result.system1_count, result.system2_count,
            result.high_motivation_count, self.MOTIVATION_THRESHOLD,
            result.stimuli_processed, result.decayed_count,
            result.cycle_duration_ms,
        )

        # Log top thoughts
        for t in sorted(all_thoughts, key=lambda x: x.motivation_score, reverse=True)[:3]:
            logger.info(
                "   üí≠ [%s] %.2f | %s",
                t.thought_type, t.motivation_score, t.content[:80]
            )

        return result
