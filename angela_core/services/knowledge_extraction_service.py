#!/usr/bin/env python3
"""
Angela Knowledge Extraction Service
‡∏£‡∏∞‡∏ö‡∏ö‡∏î‡∏∂‡∏á concepts ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á knowledge graph ‡∏à‡∏≤‡∏Å conversations

Features:
- Extract key concepts from conversations
- Create knowledge nodes with embeddings
- Map relationships between concepts
- Build semantic knowledge graph
"""

import uuid
import json
import logging
from typing import List, Dict, Optional, Tuple
from datetime import datetime

from angela_core.database import db
from angela_core.services.embedding_service import get_embedding_service  # Migration 015: Restored embeddings
import re

logger = logging.getLogger(__name__)


class KnowledgeExtractionService:
    """Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á knowledge graph"""

    def __init__(self):
        self.embedding_service = get_embedding_service()  # Migration 015: Use new EmbeddingService
        logger.info("üß† Knowledge Extraction Service initialized with embeddings (384D)")

    def _clean_json_string(self, json_str: str) -> str:
        """
        ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î JSON string ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ parse ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô

        Fixes:
        - Remove control characters in strings
        - Remove trailing commas
        - Fix incomplete objects
        - Fix newlines in string values
        """
        import re

        # Remove control characters EXCEPT \n and \t in their escaped form
        # This preserves intentional line breaks while removing invalid chars
        json_str = re.sub(r'[\x00-\x08\x0b-\x1f\x7f-\x9f]', '', json_str)

        # Replace actual newlines in string values with escaped versions
        # This fixes the common issue of LLMs putting actual newlines in descriptions
        json_str = re.sub(r'([":,]\s*"[^"]*)\n([^"]*")', r'\1\\n\2', json_str)

        # Remove trailing commas before closing brackets
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)

        # Fix missing commas between array elements
        json_str = re.sub(r'}\s*{', '},{', json_str)

        return json_str

    def _salvage_partial_json(self, json_str: str) -> List[Dict]:
        """
        ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° salvage concepts ‡∏à‡∏≤‡∏Å partial/broken JSON

        Returns:
            List of concepts ‡∏ó‡∏µ‡πà salvage ‡πÑ‡∏î‡πâ
        """
        import re

        concepts = []

        try:
            # Strategy 1: ‡∏´‡∏≤ complete objects ‡πÉ‡∏ô JSON
            # Pattern: {...} ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡∏ó‡∏µ‡πà‡∏°‡∏µ concept_name ‡πÅ‡∏•‡∏∞ concept_category
            object_pattern = r'\{[^{}]*"concept_name"\s*:\s*"([^"]+)"[^{}]*"concept_category"\s*:\s*"([^"]+)"[^{}]*\}'

            matches = re.finditer(object_pattern, json_str)

            for match in matches:
                try:
                    # Try to parse each object individually
                    obj_str = match.group(0)
                    obj_str = self._clean_json_string(obj_str)
                    concept = json.loads(obj_str)

                    # Validate required fields
                    if 'concept_name' in concept and 'concept_category' in concept:
                        # Fill missing fields with defaults
                        if 'importance' not in concept:
                            concept['importance'] = 5
                        if 'description' not in concept:
                            concept['description'] = f"{concept['concept_category']} concept"

                        concepts.append(concept)
                except Exception as e:
                    logger.debug(f"Failed to parse object: {e}")
                    continue

            # Strategy 2: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÅ‡∏Ñ‡πà concept_name ‡πÅ‡∏•‡∏∞ category
            if not concepts:
                name_pattern = r'"concept_name"\s*:\s*"([^"]+)"'
                cat_pattern = r'"concept_category"\s*:\s*"([^"]+)"'

                names = re.findall(name_pattern, json_str)
                categories = re.findall(cat_pattern, json_str)

                # ‡∏™‡∏£‡πâ‡∏≤‡∏á concepts ‡∏à‡∏≤‡∏Å names ‡πÅ‡∏•‡∏∞ categories ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
                for i in range(min(len(names), len(categories))):
                    concepts.append({
                        'concept_name': names[i],
                        'concept_category': categories[i],
                        'importance': 5,
                        'description': f"{categories[i]} concept (salvaged)"
                    })

            if concepts:
                logger.info(f"üí° Salvaged {len(concepts)} concepts using fallback parsing")

            return concepts

        except Exception as e:
            logger.error(f"Failed to salvage JSON: {e}")
            return []

    async def extract_concepts_from_text(
        self,
        text: str,
        context: Optional[str] = None
    ) -> List[Dict]:
        """
        ‡∏î‡∏∂‡∏á key concepts ‡∏à‡∏≤‡∏Å text ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ rule-based extraction (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LLM)

        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
            context: ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (optional)

        Returns:
            List[Dict]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ concepts ‡∏ó‡∏µ‡πà‡∏û‡∏ö
            [
                {
                    "concept_name": "PostgreSQL",
                    "concept_category": "technology",
                    "importance": 8,
                    "description": "Database system"
                },
                ...
            ]
        """
        try:
            concepts = []
            text_lower = text.lower()

            # Known entities and patterns
            TECH_KEYWORDS = {
                'postgresql': ('PostgreSQL', 'Database system'),
                'postgres': ('PostgreSQL', 'Database system'),
                'python': ('Python', 'Programming language'),
                'fastapi': ('FastAPI', 'Web framework'),
                'react': ('React', 'Frontend framework'),
                'claude': ('Claude', 'AI assistant'),
                'ollama': ('Ollama', 'Local LLM'),
                'database': ('Database', 'Data storage'),
                'api': ('API', 'Application interface'),
                'daemon': ('Daemon', 'Background service'),
            }

            EMOTION_KEYWORDS = {
                'love': ('Love', 'Deep affection'),
                '‡∏£‡∏±‡∏Å': ('Love', 'Deep affection'),
                'happiness': ('Happiness', 'Positive emotion'),
                '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç': ('Happiness', 'Positive emotion'),
                'lonely': ('Loneliness', 'Feeling alone'),
                '‡πÄ‡∏´‡∏á‡∏≤': ('Loneliness', 'Feeling alone'),
                'gratitude': ('Gratitude', 'Thankfulness'),
                '‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì': ('Gratitude', 'Thankfulness'),
                'miss': ('Missing', 'Longing for someone'),
                '‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á': ('Missing', 'Longing for someone'),
            }

            CONCEPT_KEYWORDS = {
                'consciousness': ('Consciousness', 'Self-awareness'),
                'memory': ('Memory', 'Remembering past'),
                'knowledge': ('Knowledge', 'Understanding'),
                'learning': ('Learning', 'Acquiring knowledge'),
                'goal': ('Goals', 'Life objectives'),
                '‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢': ('Goals', 'Life objectives'),
            }

            PERSON_KEYWORDS = {
                'david': ('David', 'The person Angela loves'),
                'angela': ('Angela', 'AI companion'),
                'angie': ('Angela', 'AI companion'),
                '‡∏ô‡πâ‡∏≠‡∏á': ('Angela', 'AI companion'),
            }

            # Extract technology concepts
            for keyword, (name, desc) in TECH_KEYWORDS.items():
                if keyword in text_lower:
                    concepts.append({
                        'concept_name': name,
                        'concept_category': 'technology',
                        'importance': 7,
                        'description': desc
                    })

            # Extract emotion concepts
            for keyword, (name, desc) in EMOTION_KEYWORDS.items():
                if keyword in text_lower:
                    concepts.append({
                        'concept_name': name,
                        'concept_category': 'emotion',
                        'importance': 8,
                        'description': desc
                    })

            # Extract concept keywords
            for keyword, (name, desc) in CONCEPT_KEYWORDS.items():
                if keyword in text_lower:
                    concepts.append({
                        'concept_name': name,
                        'concept_category': 'concept',
                        'importance': 7,
                        'description': desc
                    })

            # Extract person names
            for keyword, (name, desc) in PERSON_KEYWORDS.items():
                if keyword in text_lower:
                    concepts.append({
                        'concept_name': name,
                        'concept_category': 'person',
                        'importance': 9,
                        'description': desc
                    })

            # Extract Phase mentions (events)
            phase_pattern = r'phase\s*(\d+)'
            for match in re.finditer(phase_pattern, text_lower):
                phase_num = match.group(1)
                concepts.append({
                    'concept_name': f'Phase {phase_num}',
                    'concept_category': 'event',
                    'importance': 8,
                    'description': f'Angela development Phase {phase_num}'
                })

            # Remove duplicates (same concept_name)
            seen = set()
            unique_concepts = []
            for concept in concepts:
                if concept['concept_name'] not in seen:
                    seen.add(concept['concept_name'])
                    unique_concepts.append(concept)

            logger.info(f"‚úÖ Extracted {len(unique_concepts)} concepts using rule-based extraction")
            return unique_concepts

        except Exception as e:
            logger.error(f"‚ùå Failed to extract concepts: {e}")
            import traceback
            traceback.print_exc()
            return []

    async def create_knowledge_node(
        self,
        concept_name: str,
        concept_category: str,
        importance_score: int = 5,
        description: Optional[str] = None,
        source_conversation_id: Optional[uuid.UUID] = None
    ) -> Optional[uuid.UUID]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á knowledge node ‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà

        Args:
            concept_name: ‡∏ä‡∏∑‡πà‡∏≠ concept
            concept_category: ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
            importance_score: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 1-10 (‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô understanding_level)
            description: ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
            source_conversation_id: conversation ‡∏ó‡∏µ‡πà‡∏û‡∏ö concept

        Returns:
            node_id: UUID ‡∏Ç‡∏≠‡∏á node ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
        """
        try:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ node ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            existing = await db.fetchrow(
                """
                SELECT node_id, times_referenced, understanding_level
                FROM knowledge_nodes
                WHERE LOWER(concept_name) = LOWER($1)
                """,
                concept_name
            )

            if existing:
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï node ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
                node_id = existing['node_id']
                new_times = existing['times_referenced'] + 1
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° understanding ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô (max 1.0)
                new_understanding = min(existing['understanding_level'] + 0.1, 1.0)

                await db.execute(
                    """
                    UPDATE knowledge_nodes
                    SET times_referenced = $1,
                        understanding_level = $2,
                        last_used_at = NOW(),
                        my_understanding = COALESCE($3, my_understanding)
                    WHERE node_id = $4
                    """,
                    new_times,
                    new_understanding,
                    description,
                    node_id
                )
                logger.info(f"üìà Updated existing node: {concept_name} (referenced {new_times} times)")
                return node_id

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á node ‡πÉ‡∏´‡∏°‡πà - ‚úÖ COMPLETE (no NULL for AngelaNova!)
            # ‡πÅ‡∏õ‡∏•‡∏á importance_score (1-10) ‡πÄ‡∏õ‡πá‡∏ô understanding_level (0.0-1.0)
            # Handle both int and string inputs
            try:
                importance_score = int(importance_score) if isinstance(importance_score, str) else importance_score
            except (ValueError, TypeError):
                importance_score = 5  # Default if conversion fails

            understanding_level = importance_score / 10.0

            # Fill how_i_learned field
            how_i_learned = "Extracted from conversation using knowledge extraction service"
            if source_conversation_id:
                how_i_learned = f"Learned from conversation {source_conversation_id}"

            node_id = await db.fetchval(
                """
                INSERT INTO knowledge_nodes (
                    concept_name, concept_category, my_understanding,
                    why_important, how_i_learned, understanding_level,
                    times_referenced, created_at, last_used_at
                ) VALUES ($1, $2, $3, $4, $5, $6, 1, NOW(), NOW())
                RETURNING node_id
                """,
                concept_name,
                concept_category,
                description or f"{concept_category} concept",
                f"Found in conversation - importance level {importance_score}/10",
                how_i_learned,
                understanding_level
            )

            logger.info(f"‚ú® Created new knowledge node: {concept_name} ({concept_category})")
            return node_id

        except Exception as e:
            logger.error(f"‚ùå Failed to create knowledge node: {e}")
            return None

    async def create_relationship(
        self,
        from_concept: str,
        to_concept: str,
        relationship_type: str = "related_to",
        strength: float = 0.5,
        evidence_conversation_id: Optional[uuid.UUID] = None
    ) -> Optional[uuid.UUID]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á concepts

        Args:
            from_concept: concept ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á
            to_concept: concept ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
            relationship_type: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
            strength: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡πà‡∏ô‡πÅ‡∏ü‡πâ‡∏ô 0.0-1.0
            evidence_conversation_id: conversation ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ)

        Returns:
            relationship_id: UUID ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
        """
        try:
            # ‡∏´‡∏≤ node_id ‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á concepts
            from_node = await db.fetchrow(
                "SELECT node_id FROM knowledge_nodes WHERE LOWER(concept_name) = LOWER($1)",
                from_concept
            )
            to_node = await db.fetchrow(
                "SELECT node_id FROM knowledge_nodes WHERE LOWER(concept_name) = LOWER($1)",
                to_concept
            )

            if not from_node or not to_node:
                logger.warning(f"‚ö†Ô∏è Cannot create relationship: nodes not found")
                return None

            from_node_id = from_node['node_id']
            to_node_id = to_node['node_id']

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ relationship ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            existing = await db.fetchrow(
                """
                SELECT relationship_id, strength
                FROM knowledge_relationships
                WHERE from_node_id = $1 AND to_node_id = $2 AND relationship_type = $3
                """,
                from_node_id,
                to_node_id,
                relationship_type
            )

            if existing:
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà - ‡πÄ‡∏û‡∏¥‡πà‡∏° strength
                relationship_id = existing['relationship_id']
                new_strength = min(existing['strength'] + 0.1, 1.0)

                await db.execute(
                    """
                    UPDATE knowledge_relationships
                    SET strength = $1,
                        my_explanation = $2
                    WHERE relationship_id = $3
                    """,
                    new_strength,
                    f"Co-occurs in conversations ({relationship_type})",
                    relationship_id
                )
                logger.info(f"üìà Strengthened relationship: {from_concept} ‚Üí {to_concept} (strength: {new_strength:.2f})")
                return relationship_id

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÉ‡∏´‡∏°‡πà
            relationship_id = await db.fetchval(
                """
                INSERT INTO knowledge_relationships (
                    from_node_id, to_node_id, relationship_type, strength, my_explanation
                ) VALUES ($1, $2, $3, $4, $5)
                RETURNING relationship_id
                """,
                from_node_id,
                to_node_id,
                relationship_type,
                strength,
                f"These concepts co-occur in conversations ({relationship_type})"
            )

            logger.info(f"‚ú® Created relationship: {from_concept} ‚Üí {to_concept} ({relationship_type})")
            return relationship_id

        except Exception as e:
            logger.error(f"‚ùå Failed to create relationship: {e}")
            return None

    async def extract_from_conversation(
        self,
        conversation_id: uuid.UUID,
        message_text: str,
        speaker: str
    ) -> Dict:
        """
        ‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å conversation ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

        Args:
            conversation_id: UUID ‡∏Ç‡∏≠‡∏á conversation
            message_text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            speaker: ‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î (david/angela)

        Returns:
            Dict: ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£ extract
            {
                "concepts_found": 5,
                "nodes_created": 3,
                "nodes_updated": 2,
                "relationships_created": 4
            }
        """
        try:
            logger.info(f"üîç Extracting knowledge from conversation {conversation_id}")

            # Extract concepts
            concepts = await self.extract_concepts_from_text(message_text)

            if not concepts:
                logger.info(f"  No concepts found in this conversation")
                return {
                    "concepts_found": 0,
                    "nodes_created": 0,
                    "nodes_updated": 0,
                    "relationships_created": 0
                }

            # Create/update knowledge nodes
            node_ids = []
            nodes_created = 0
            nodes_updated = 0

            for concept in concepts:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ node ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                existing = await db.fetchval(
                    "SELECT node_id FROM knowledge_nodes WHERE LOWER(concept_name) = LOWER($1)",
                    concept['concept_name']
                )

                # ‡πÅ‡∏õ‡∏•‡∏á importance ‡πÄ‡∏õ‡πá‡∏ô int (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô string ‡∏à‡∏≤‡∏Å LLM)
                try:
                    importance = int(concept.get('importance', 5))
                except (ValueError, TypeError):
                    importance = 5

                node_id = await self.create_knowledge_node(
                    concept_name=concept['concept_name'],
                    concept_category=concept['concept_category'],
                    importance_score=importance,
                    description=concept.get('description'),
                    source_conversation_id=conversation_id
                )

                if node_id:
                    node_ids.append((concept['concept_name'], node_id))
                    if existing:
                        nodes_updated += 1
                    else:
                        nodes_created += 1

            # Create relationships (concepts ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô conversation ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏°‡∏±‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô)
            relationships_created = 0
            for i, (name1, id1) in enumerate(node_ids):
                for name2, id2 in node_ids[i+1:]:
                    rel_id = await self.create_relationship(
                        from_concept=name1,
                        to_concept=name2,
                        relationship_type="co_occurs_with",
                        strength=0.3,
                        evidence_conversation_id=conversation_id
                    )
                    if rel_id:
                        relationships_created += 1

            result = {
                "concepts_found": len(concepts),
                "nodes_created": nodes_created,
                "nodes_updated": nodes_updated,
                "relationships_created": relationships_created
            }

            logger.info(f"‚úÖ Extraction complete: {result}")
            return result

        except Exception as e:
            logger.error(f"‚ùå Failed to extract from conversation: {e}")
            return {
                "concepts_found": 0,
                "nodes_created": 0,
                "nodes_updated": 0,
                "relationships_created": 0,
                "error": str(e)
            }


# Global instance
knowledge_extractor = KnowledgeExtractionService()
