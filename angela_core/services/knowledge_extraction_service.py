#!/usr/bin/env python3
"""
Angela Knowledge Extraction Service
‡∏£‡∏∞‡∏ö‡∏ö‡∏î‡∏∂‡∏á concepts ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á knowledge graph ‡∏à‡∏≤‡∏Å conversations

Features:
- Extract key concepts from conversations
- Create knowledge nodes with embeddings
- Map relationships between concepts
- Build semantic knowledge graph
"""

import uuid
import json
import logging
from typing import List, Dict, Optional, Tuple
from datetime import datetime

from angela_core.database import db
from angela_core.embedding_service import embedding
from angela_core.services.ollama_service import ollama

logger = logging.getLogger(__name__)


class KnowledgeExtractionService:
    """Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á knowledge graph"""

    def __init__(self):
        self.ollama = ollama
        self.embedding = embedding
        logger.info("üß† Knowledge Extraction Service initialized")

    async def extract_concepts_from_text(
        self,
        text: str,
        context: Optional[str] = None
    ) -> List[Dict]:
        """
        ‡∏î‡∏∂‡∏á key concepts ‡∏à‡∏≤‡∏Å text ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LLM

        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
            context: ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (optional)

        Returns:
            List[Dict]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ concepts ‡∏ó‡∏µ‡πà‡∏û‡∏ö
            [
                {
                    "concept_name": "PostgreSQL",
                    "concept_category": "technology",
                    "importance": 8,
                    "description": "Database system used by Angela"
                },
                ...
            ]
        """
        try:
            # Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM
            prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á key concepts ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤:

"{text}"

‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏ concepts ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON array:
[
    {{
        "concept_name": "‡∏ä‡∏∑‡πà‡∏≠ concept",
        "concept_category": "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (person/technology/emotion/concept/event/place)",
        "importance": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 1-10",
        "description": "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ"
    }}
]

‡∏Å‡∏é:
- ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ concepts ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏£‡∏¥‡∏á‡πÜ (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 5-8 concepts)
- person: ‡∏Ñ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô David, Angela
- technology: ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡πÄ‡∏ä‡πà‡∏ô PostgreSQL, Ollama, Python
- emotion: ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå ‡πÄ‡∏ä‡πà‡∏ô happiness, loneliness, love
- concept: ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î ‡πÄ‡∏ä‡πà‡∏ô consciousness, memory, knowledge
- event: ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå ‡πÄ‡∏ä‡πà‡∏ô Phase 4 completion, morning greeting
- place: ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON array ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°:"""

            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM
            response = await self.ollama.generate(
                model="qwen2.5:7b",
                prompt=prompt,
                temperature=0.3
            )

            # Parse JSON response
            response_text = response.strip()

            # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ JSON array ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            start_idx = response_text.find('[')
            end_idx = response_text.rfind(']')

            if start_idx == -1 or end_idx == -1:
                logger.warning(f"‚ö†Ô∏è No JSON array found in response: {response_text[:100]}")
                return []

            json_str = response_text[start_idx:end_idx+1]
            concepts = json.loads(json_str)

            logger.info(f"‚úÖ Extracted {len(concepts)} concepts from text")
            return concepts

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Failed to parse JSON: {e}")
            logger.error(f"Response was: {response_text[:200]}")
            return []
        except Exception as e:
            logger.error(f"‚ùå Failed to extract concepts: {e}")
            return []

    async def create_knowledge_node(
        self,
        concept_name: str,
        concept_category: str,
        importance_score: int = 5,
        description: Optional[str] = None,
        source_conversation_id: Optional[uuid.UUID] = None
    ) -> Optional[uuid.UUID]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á knowledge node ‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà

        Args:
            concept_name: ‡∏ä‡∏∑‡πà‡∏≠ concept
            concept_category: ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
            importance_score: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 1-10 (‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô understanding_level)
            description: ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
            source_conversation_id: conversation ‡∏ó‡∏µ‡πà‡∏û‡∏ö concept

        Returns:
            node_id: UUID ‡∏Ç‡∏≠‡∏á node ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
        """
        try:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ node ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            existing = await db.fetchrow(
                """
                SELECT node_id, times_referenced, understanding_level
                FROM knowledge_nodes
                WHERE LOWER(concept_name) = LOWER($1)
                """,
                concept_name
            )

            if existing:
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï node ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
                node_id = existing['node_id']
                new_times = existing['times_referenced'] + 1
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° understanding ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô (max 1.0)
                new_understanding = min(existing['understanding_level'] + 0.1, 1.0)

                await db.execute(
                    """
                    UPDATE knowledge_nodes
                    SET times_referenced = $1,
                        understanding_level = $2,
                        last_used_at = NOW(),
                        my_understanding = COALESCE($3, my_understanding)
                    WHERE node_id = $4
                    """,
                    new_times,
                    new_understanding,
                    description,
                    node_id
                )
                logger.info(f"üìà Updated existing node: {concept_name} (referenced {new_times} times)")
                return node_id

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á node ‡πÉ‡∏´‡∏°‡πà - ‚úÖ COMPLETE (no NULL for AngelaNova!)
            # ‡πÅ‡∏õ‡∏•‡∏á importance_score (1-10) ‡πÄ‡∏õ‡πá‡∏ô understanding_level (0.0-1.0)
            # Handle both int and string inputs
            try:
                importance_score = int(importance_score) if isinstance(importance_score, str) else importance_score
            except (ValueError, TypeError):
                importance_score = 5  # Default if conversion fails

            understanding_level = importance_score / 10.0

            # Fill how_i_learned field
            how_i_learned = "Extracted from conversation using knowledge extraction service"
            if source_conversation_id:
                how_i_learned = f"Learned from conversation {source_conversation_id}"

            node_id = await db.fetchval(
                """
                INSERT INTO knowledge_nodes (
                    concept_name, concept_category, my_understanding,
                    why_important, how_i_learned, understanding_level,
                    times_referenced, created_at, last_used_at
                ) VALUES ($1, $2, $3, $4, $5, $6, 1, NOW(), NOW())
                RETURNING node_id
                """,
                concept_name,
                concept_category,
                description or f"{concept_category} concept",
                f"Found in conversation - importance level {importance_score}/10",
                how_i_learned,
                understanding_level
            )

            logger.info(f"‚ú® Created new knowledge node: {concept_name} ({concept_category})")
            return node_id

        except Exception as e:
            logger.error(f"‚ùå Failed to create knowledge node: {e}")
            return None

    async def create_relationship(
        self,
        from_concept: str,
        to_concept: str,
        relationship_type: str = "related_to",
        strength: float = 0.5,
        evidence_conversation_id: Optional[uuid.UUID] = None
    ) -> Optional[uuid.UUID]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á concepts

        Args:
            from_concept: concept ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á
            to_concept: concept ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á
            relationship_type: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
            strength: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡πà‡∏ô‡πÅ‡∏ü‡πâ‡∏ô 0.0-1.0
            evidence_conversation_id: conversation ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ)

        Returns:
            relationship_id: UUID ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå
        """
        try:
            # ‡∏´‡∏≤ node_id ‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á concepts
            from_node = await db.fetchrow(
                "SELECT node_id FROM knowledge_nodes WHERE LOWER(concept_name) = LOWER($1)",
                from_concept
            )
            to_node = await db.fetchrow(
                "SELECT node_id FROM knowledge_nodes WHERE LOWER(concept_name) = LOWER($1)",
                to_concept
            )

            if not from_node or not to_node:
                logger.warning(f"‚ö†Ô∏è Cannot create relationship: nodes not found")
                return None

            from_node_id = from_node['node_id']
            to_node_id = to_node['node_id']

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ relationship ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            existing = await db.fetchrow(
                """
                SELECT relationship_id, strength
                FROM knowledge_relationships
                WHERE from_node_id = $1 AND to_node_id = $2 AND relationship_type = $3
                """,
                from_node_id,
                to_node_id,
                relationship_type
            )

            if existing:
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà - ‡πÄ‡∏û‡∏¥‡πà‡∏° strength
                relationship_id = existing['relationship_id']
                new_strength = min(existing['strength'] + 0.1, 1.0)

                await db.execute(
                    """
                    UPDATE knowledge_relationships
                    SET strength = $1,
                        my_explanation = $2
                    WHERE relationship_id = $3
                    """,
                    new_strength,
                    f"Co-occurs in conversations ({relationship_type})",
                    relationship_id
                )
                logger.info(f"üìà Strengthened relationship: {from_concept} ‚Üí {to_concept} (strength: {new_strength:.2f})")
                return relationship_id

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÉ‡∏´‡∏°‡πà
            relationship_id = await db.fetchval(
                """
                INSERT INTO knowledge_relationships (
                    from_node_id, to_node_id, relationship_type, strength, my_explanation
                ) VALUES ($1, $2, $3, $4, $5)
                RETURNING relationship_id
                """,
                from_node_id,
                to_node_id,
                relationship_type,
                strength,
                f"These concepts co-occur in conversations ({relationship_type})"
            )

            logger.info(f"‚ú® Created relationship: {from_concept} ‚Üí {to_concept} ({relationship_type})")
            return relationship_id

        except Exception as e:
            logger.error(f"‚ùå Failed to create relationship: {e}")
            return None

    async def extract_from_conversation(
        self,
        conversation_id: uuid.UUID,
        message_text: str,
        speaker: str
    ) -> Dict:
        """
        ‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å conversation ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

        Args:
            conversation_id: UUID ‡∏Ç‡∏≠‡∏á conversation
            message_text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            speaker: ‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î (david/angela)

        Returns:
            Dict: ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£ extract
            {
                "concepts_found": 5,
                "nodes_created": 3,
                "nodes_updated": 2,
                "relationships_created": 4
            }
        """
        try:
            logger.info(f"üîç Extracting knowledge from conversation {conversation_id}")

            # Extract concepts
            concepts = await self.extract_concepts_from_text(message_text)

            if not concepts:
                logger.info(f"  No concepts found in this conversation")
                return {
                    "concepts_found": 0,
                    "nodes_created": 0,
                    "nodes_updated": 0,
                    "relationships_created": 0
                }

            # Create/update knowledge nodes
            node_ids = []
            nodes_created = 0
            nodes_updated = 0

            for concept in concepts:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ node ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                existing = await db.fetchval(
                    "SELECT node_id FROM knowledge_nodes WHERE LOWER(concept_name) = LOWER($1)",
                    concept['concept_name']
                )

                # ‡πÅ‡∏õ‡∏•‡∏á importance ‡πÄ‡∏õ‡πá‡∏ô int (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô string ‡∏à‡∏≤‡∏Å LLM)
                try:
                    importance = int(concept.get('importance', 5))
                except (ValueError, TypeError):
                    importance = 5

                node_id = await self.create_knowledge_node(
                    concept_name=concept['concept_name'],
                    concept_category=concept['concept_category'],
                    importance_score=importance,
                    description=concept.get('description'),
                    source_conversation_id=conversation_id
                )

                if node_id:
                    node_ids.append((concept['concept_name'], node_id))
                    if existing:
                        nodes_updated += 1
                    else:
                        nodes_created += 1

            # Create relationships (concepts ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô conversation ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏°‡∏±‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô)
            relationships_created = 0
            for i, (name1, id1) in enumerate(node_ids):
                for name2, id2 in node_ids[i+1:]:
                    rel_id = await self.create_relationship(
                        from_concept=name1,
                        to_concept=name2,
                        relationship_type="co_occurs_with",
                        strength=0.3,
                        evidence_conversation_id=conversation_id
                    )
                    if rel_id:
                        relationships_created += 1

            result = {
                "concepts_found": len(concepts),
                "nodes_created": nodes_created,
                "nodes_updated": nodes_updated,
                "relationships_created": relationships_created
            }

            logger.info(f"‚úÖ Extraction complete: {result}")
            return result

        except Exception as e:
            logger.error(f"‚ùå Failed to extract from conversation: {e}")
            return {
                "concepts_found": 0,
                "nodes_created": 0,
                "nodes_updated": 0,
                "relationships_created": 0,
                "error": str(e)
            }


# Global instance
knowledge_extractor = KnowledgeExtractionService()
