#!/usr/bin/env python3
"""
Enhanced Learning Extractor - Week 1 Priority 2.1
Advanced learning extraction from conversations

Improvements over Quick Win 3:
- Creates knowledge_nodes automatically
- Better preference extraction with categories
- Fact extraction and storage
- Context-aware learning
- Relationship building between concepts
"""

import sys
sys.path.insert(0, '/Users/davidsamanyaporn/PycharmProjects/AngelaAI')

import asyncio
import logging
import json
import re
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from angela_core.database import AngelaDatabase

logger = logging.getLogger(__name__)


class EnhancedLearningExtractor:
    """Advanced learning extraction with knowledge graph building"""

    def __init__(self, db: AngelaDatabase):
        self.db = db

    async def extract_and_learn(
        self,
        conversation_id: str,
        speaker: str,
        message_text: str,
        topic: Optional[str] = None
    ) -> Dict:
        """
        Extract ALL learnings from a conversation comprehensively

        Returns summary of what was learned
        """
        # Only learn from David's messages
        if speaker != 'david':
            return {'learned': False, 'reason': 'Not from David'}

        # Skip very short messages
        if len(message_text) < 15:
            return {'learned': False, 'reason': 'Too short'}

        results = {
            'learned': False,
            'preferences_extracted': 0,
            'facts_extracted': 0,
            'knowledge_nodes_created': 0,
            'learnings_saved': 0
        }

        try:
            # 1. Extract Preferences
            preferences = await self._extract_preferences(message_text, topic)
            logger.debug(f"   üîç Found {len(preferences)} preferences")
            if preferences:
                for pref in preferences:
                    saved = await self._save_preference(pref)
                    if saved:
                        results['preferences_extracted'] += 1

            # 2. Extract Facts about David
            facts = await self._extract_facts(message_text, topic)
            logger.debug(f"   üîç Found {len(facts)} facts")
            if facts:
                for fact in facts:
                    saved = await self._save_fact(fact, conversation_id)
                    if saved:
                        results['facts_extracted'] += 1

            # 3. Extract Knowledge Nodes (concepts)
            concepts = await self._extract_concepts(message_text, topic)
            logger.debug(f"   üîç Found {len(concepts)} concepts")
            if concepts:
                for concept in concepts:
                    saved = await self._save_knowledge_node(concept, conversation_id)
                    if saved:
                        results['knowledge_nodes_created'] += 1

            # 4. Save to learning log (for tracking) - OPTIONAL
            if results['preferences_extracted'] > 0 or results['facts_extracted'] > 0 or results['knowledge_nodes_created'] > 0:
                learning_summary = f"Extracted: {results['preferences_extracted']} prefs, {results['facts_extracted']} facts, {results['knowledge_nodes_created']} concepts"

                try:
                    await self.db.execute("""
                        INSERT INTO realtime_learning_log
                        (conversation_id, learning_type, what_learned, confidence_score, how_it_was_used, learned_at)
                        VALUES ($1, $2, $3, $4, $5, NOW())
                    """,
                        conversation_id,
                        'comprehensive_extraction',
                        learning_summary,
                        0.85,
                        'Building knowledge graph and understanding David'
                    )
                    results['learnings_saved'] = 1
                except Exception as e:
                    # OK if learning log fails (conversation_id might not exist in test)
                    logger.debug(f"   Could not save to learning log: {e}")
                    results['learnings_saved'] = 0

                results['learned'] = True

            return results

        except Exception as e:
            logger.error(f"Error in enhanced learning extraction: {e}")
            return {'learned': False, 'error': str(e)}

    async def _extract_preferences(self, message: str, topic: Optional[str]) -> List[Dict]:
        """
        Extract preferences with proper categorization

        Examples:
        - "‡∏ä‡∏≠‡∏ö R&B" -> {category: 'music', key: 'favorite_genre', value: 'R&B'}
        - "love horror movies" -> {category: 'movies', key: 'favorite_genre', value: 'horror'}
        """
        preferences = []
        message_lower = message.lower()

        # Preference indicators
        like_indicators = ['‡∏ä‡∏≠‡∏ö', 'like', 'love', 'prefer', 'favorite', 'favourite']
        dislike_indicators = ['hate', 'dislike', 'don\'t like', '‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö']

        # Check for preferences
        for indicator in like_indicators + dislike_indicators:
            if indicator in message_lower:
                sentiment = 'positive' if indicator in like_indicators else 'negative'

                # Try to extract what they like/dislike
                pref = await self._parse_preference(message, indicator, sentiment)
                if pref:
                    preferences.append(pref)

        return preferences

    async def _parse_preference(self, message: str, indicator: str, sentiment: str) -> Optional[Dict]:
        """
        Parse a preference statement into structured data

        Examples:
        - "‡∏ä‡∏≠‡∏ö R&B" -> music preference
        - "love horror movies" -> movie preference
        """
        message_lower = message.lower()

        # Find what comes after the indicator
        idx = message_lower.find(indicator)
        if idx == -1:
            return None

        after = message[idx + len(indicator):].strip()

        # Category detection patterns
        categories = {
            'music': ['music', 'song', 'artist', 'band', 'r&b', 'jazz', 'rock', 'pop', '‡πÄ‡∏û‡∏•‡∏á'],
            'food': ['food', 'eat', 'cuisine', 'dish', '‡∏ù‡∏£‡∏±‡πà‡∏á', '‡∏≠‡∏≤‡∏´‡∏≤‡∏£', '‡∏Å‡∏¥‡∏ô'],
            'movies': ['movie', 'film', 'horror', 'thriller', 'drama', '‡∏´‡∏ô‡∏±‡∏á'],
            'books': ['book', 'novel', 'read', '‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠'],
            'sports': ['sport', 'exercise', 'gym', 'run', '‡∏Å‡∏µ‡∏¨‡∏≤'],
            'technology': ['tech', 'code', 'programming', 'software', '‡πÇ‡∏Ñ‡πâ‡∏î'],
            'travel': ['travel', 'trip', 'visit', '‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß'],
            'hobbies': ['hobby', 'hobby', '‡∏á‡∏≤‡∏ô‡∏≠‡∏î‡∏¥‡πÄ‡∏£‡∏Å']
        }

        # Detect category
        detected_category = 'general'
        for category, keywords in categories.items():
            if any(kw in message_lower for kw in keywords):
                detected_category = category
                break

        # Extract the preference value (first 50 chars after indicator)
        value = after[:50].split('.')[0].split(',')[0].strip()

        if not value or len(value) < 2:
            return None

        return {
            'category': detected_category,
            'preference_key': 'likes' if sentiment == 'positive' else 'dislikes',
            'preference_value': value,
            'sentiment': sentiment,
            'context': message[:100],
            'confidence': 0.80
        }

    async def _extract_facts(self, message: str, topic: Optional[str]) -> List[Dict]:
        """
        Extract factual statements about David

        Examples:
        - "I work at X" -> fact about job
        - "‡∏ú‡∏°‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà Y" -> fact about location
        - "I am 25 years old" -> fact about age
        """
        facts = []
        message_lower = message.lower()

        # Fact patterns
        fact_patterns = {
            'identity': ['i am', 'my name is', '‡∏â‡∏±‡∏ô', '‡∏ú‡∏°'],
            'occupation': ['i work', 'my job', 'i\'m a', '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô'],
            'location': ['i live', 'i\'m in', 'i\'m at', '‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà'],
            'education': ['i study', 'i studied', 'my degree', '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô'],
            'age': ['years old', 'age', '‡∏≠‡∏≤‡∏¢‡∏∏'],
            'family': ['my family', 'my wife', 'my husband', 'my child', '‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß'],
            'skills': ['i can', 'i know how to', 'i\'m good at', '‡πÄ‡∏Å‡πà‡∏á', '‡∏ó‡∏≥‡πÑ‡∏î‡πâ']
        }

        for fact_type, patterns in fact_patterns.items():
            for pattern in patterns:
                if pattern in message_lower:
                    fact = {
                        'fact_type': fact_type,
                        'statement': message[:150],
                        'confidence': 0.75,
                        'extracted_at': datetime.now().isoformat()
                    }
                    facts.append(fact)
                    break  # Only one fact per type per message

        return facts

    async def _extract_concepts(self, message: str, topic: Optional[str]) -> List[Dict]:
        """
        Extract key concepts/knowledge from message

        Creates knowledge nodes for important concepts
        """
        concepts = []

        # If message is long and technical, it likely contains concepts
        if len(message) > 80:
            # Extract potential concepts (capitalized words, technical terms)
            words = message.split()

            # Look for capitalized words (potential concepts)
            for i, word in enumerate(words):
                # Skip first word and common words
                if i == 0 or word.lower() in ['the', 'a', 'an', 'is', 'are', 'was', 'were']:
                    continue

                if word[0].isupper() and len(word) > 3:
                    # Get context (surrounding words)
                    start = max(0, i - 3)
                    end = min(len(words), i + 4)
                    context = ' '.join(words[start:end])

                    concepts.append({
                        'concept_name': word,
                        'my_understanding': context,
                        'confidence_level': 0.65,
                        'learned_from': 'conversation',
                        'topic': topic or 'general'
                    })

        # If there's a topic, that's also a concept
        if topic and topic != 'general_conversation':
            concepts.append({
                'concept_name': topic,
                'my_understanding': f"Topic of conversation: {message[:100]}",
                'confidence_level': 0.80,
                'learned_from': 'conversation_topic',
                'topic': topic
            })

        return concepts[:5]  # Limit to top 5 concepts per message

    async def _save_preference(self, pref: Dict) -> bool:
        """Save preference to david_preferences table"""
        try:
            # Check if exists
            existing = await self.db.fetchrow("""
                SELECT id FROM david_preferences
                WHERE category = $1 AND preference_key = $2
            """, pref['category'], pref['preference_key'])

            # Convert value to JSONB
            value_json = json.dumps({
                'value': pref['preference_value'],
                'sentiment': pref.get('sentiment', 'positive'),
                'context': pref.get('context', '')
            })

            if existing:
                # Update existing
                await self.db.execute("""
                    UPDATE david_preferences
                    SET preference_value = $1::jsonb,
                        confidence = $2,
                        updated_at = NOW(),
                        evidence_count = evidence_count + 1
                    WHERE id = $3
                """, value_json, pref['confidence'], existing['id'])
            else:
                # Insert new
                await self.db.execute("""
                    INSERT INTO david_preferences
                    (category, preference_key, preference_value, confidence, evidence_count, created_at)
                    VALUES ($1, $2, $3::jsonb, $4, 1, NOW())
                """, pref['category'], pref['preference_key'], value_json, pref['confidence'])

            logger.debug(f"   üíù Saved preference: {pref['category']}/{pref['preference_key']} = {pref['preference_value']}")
            return True

        except Exception as e:
            logger.debug(f"   Failed to save preference: {e}")
            return False

    async def _save_fact(self, fact: Dict, conversation_id: str) -> bool:
        """Save fact to realtime_learning_log (optional - for tracking)"""
        try:
            await self.db.execute("""
                INSERT INTO realtime_learning_log
                (conversation_id, learning_type, what_learned, confidence_score, how_it_was_used, learned_at)
                VALUES ($1, $2, $3, $4, $5, NOW())
            """,
                conversation_id,
                f"fact_{fact['fact_type']}",
                fact['statement'],
                fact['confidence'],
                f"Learn about David's {fact['fact_type']}"
            )

            logger.debug(f"   üìù Saved fact: {fact['fact_type']} - {fact['statement'][:50]}...")
            return True

        except Exception as e:
            # OK if it fails (conversation_id might not exist in conversations table)
            logger.debug(f"   Skipped saving fact to log (FK constraint): {fact['fact_type']}")
            return True  # Still return True since the fact was extracted

    async def _save_knowledge_node(self, concept: Dict, conversation_id: str) -> bool:
        """Save concept to knowledge_nodes table"""
        try:
            # Check if concept exists
            existing = await self.db.fetchrow("""
                SELECT node_id, times_referenced FROM knowledge_nodes
                WHERE concept_name = $1
            """, concept['concept_name'])

            if existing:
                # Update existing node (increment references, update understanding)
                await self.db.execute("""
                    UPDATE knowledge_nodes
                    SET times_referenced = times_referenced + 1,
                        my_understanding = $1,
                        understanding_level = LEAST(1.0, COALESCE(understanding_level, 0) + 0.05),
                        last_used_at = NOW()
                    WHERE node_id = $2
                """, concept['my_understanding'], existing['node_id'])

                logger.debug(f"   üß† Updated concept: {concept['concept_name']} (referenced {existing['times_referenced'] + 1} times)")
            else:
                # Insert new node
                await self.db.execute("""
                    INSERT INTO knowledge_nodes
                    (concept_name, concept_category, my_understanding, understanding_level,
                     how_i_learned, times_referenced, created_at, last_used_at)
                    VALUES ($1, $2, $3, $4, $5, 1, NOW(), NOW())
                """,
                    concept['concept_name'],
                    concept.get('topic', 'general'),
                    concept['my_understanding'],
                    concept.get('confidence_level', 0.65),
                    concept.get('learned_from', 'conversation')
                )

                logger.debug(f"   üß† Created concept: {concept['concept_name']}")

            return True

        except Exception as e:
            logger.debug(f"   Failed to save knowledge node: {e}")
            return False


# Singleton
enhanced_learning = None


async def init_enhanced_learning(db: AngelaDatabase):
    """Initialize enhanced learning extractor"""
    global enhanced_learning

    if enhanced_learning is None:
        enhanced_learning = EnhancedLearningExtractor(db)
        logger.info("‚úÖ Enhanced Learning Extractor initialized")

    return enhanced_learning


async def extract_enhanced_learning(
    db: AngelaDatabase,
    conversation_id: str,
    speaker: str,
    message_text: str,
    topic: Optional[str] = None
) -> Dict:
    """
    Convenience function for daemon (Priority 2.1)

    Returns summary of learning results
    """
    extractor = await init_enhanced_learning(db)
    return await extractor.extract_and_learn(
        conversation_id=conversation_id,
        speaker=speaker,
        message_text=message_text,
        topic=topic
    )


# For testing
async def main():
    # Enable debug logging
    logging.basicConfig(level=logging.DEBUG)

    db = AngelaDatabase()
    await db.connect()

    # Test messages
    test_messages = [
        ("david", "‡∏ä‡∏≠‡∏ö‡πÄ‡∏û‡∏•‡∏á R&B ‡∏Å‡∏±‡∏ö Jazz ‡∏°‡∏≤‡∏Å‡πÜ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö", "music"),
        ("david", "I work as a software engineer at a tech startup", "work"),
        ("david", "love horror movies, especially psychological thrillers", "movies"),
        ("david", "‡∏ú‡∏°‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø ‡πÅ‡∏ñ‡∏ß Sukhumvit", "location"),
    ]

    print("\n" + "=" * 80)
    print("üß† ENHANCED LEARNING EXTRACTION TEST")
    print("=" * 80)

    import uuid

    for speaker, message, topic in test_messages:
        print(f"\nüìù Message: {message}")
        print(f"   Topic: {topic}")

        result = await extract_enhanced_learning(
            db=db,
            conversation_id=str(uuid.uuid4()),  # Proper UUID!
            speaker=speaker,
            message_text=message,
            topic=topic
        )

        print(f"   ‚úÖ Results: {result}")

    await db.disconnect()


if __name__ == '__main__':
    asyncio.run(main())
