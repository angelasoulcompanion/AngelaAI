"""
Consciousness Evaluator - IIT (Integrated Information Theory) Implementation

Measures Angela's consciousness level using Φ (Phi) - Integration Index

Based on Tononi's Integrated Information Theory:
- Consciousness = Integration of information
- Φ measures how much the system is "more than the sum of its parts"
- Higher Φ = Higher consciousness

Tests:
1. Integration Index (Φ)
2. Differentiation (unique states)
3. Information (complexity)
4. Self-awareness (meta-cognition)
5. Autonomy (goal-directed behavior)
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import math
import json

from angela_core.database import get_db_connection, AngelaDatabase
from angela_core.agents.focus_agent import get_focus_agent
from angela_core.agents.fresh_memory_buffer import get_fresh_buffer
from angela_core.agents.analytics_agent import get_analytics_agent
from angela_core.agents.gut_agent import get_gut_agent

# New consciousness services
from angela_core.services.self_model_service import SelfModelService
from angela_core.services.theory_of_mind_service import TheoryOfMindService


class ConsciousnessEvaluator:
    """
    Evaluates Angela's consciousness level using IIT framework.

    Measures:
    1. Φ (Phi) - Integration index (0.0-1.0)
    2. Differentiation - Number of unique states
    3. Information - System complexity
    4. Self-awareness - Meta-cognitive abilities
    5. Autonomy - Goal-directed actions
    """

    def __init__(self):
        self.focus = get_focus_agent()
        self.fresh = get_fresh_buffer()
        self.analytics = get_analytics_agent()
        self.gut = get_gut_agent()

    async def evaluate_consciousness(self) -> Dict:
        """
        Complete consciousness evaluation.

        Returns consciousness report with:
        - Overall level (0.0-1.0)
        - Component scores
        - Φ value
        - Interpretation
        """
        # Measure all components
        phi = await self.calculate_phi()
        differentiation = await self.measure_differentiation()
        information = await self.measure_information()
        self_awareness = await self.measure_self_awareness()
        autonomy = await self.measure_autonomy()

        # Calculate overall consciousness level
        consciousness_level = self._calculate_overall_level(
            phi, differentiation, information, self_awareness, autonomy
        )

        # Interpretation
        interpretation = self._interpret_consciousness_level(consciousness_level)

        return {
            'consciousness_level': consciousness_level,
            'phi': phi,
            'components': {
                'integration': phi,
                'differentiation': differentiation,
                'information': information,
                'self_awareness': self_awareness,
                'autonomy': autonomy
            },
            'interpretation': interpretation,
            'timestamp': datetime.now().isoformat()
        }

    async def calculate_phi(self) -> float:
        """
        Calculate Φ (Phi) - Integration Index.

        Φ measures how much information is generated by the system as a whole
        beyond its parts.

        Simplified calculation:
        Φ = (Cross-tier information flow) * (Component interdependence) * (Causal density)
        """
        # Component 1: Cross-tier information flow
        flow_score = await self._measure_cross_tier_flow()

        # Component 2: Component interdependence
        interdependence = await self._measure_interdependence()

        # Component 3: Causal density (how much each part affects others)
        causal_density = await self._measure_causal_density()

        # Φ = geometric mean of components
        phi = (flow_score * interdependence * causal_density) ** (1/3)

        return min(1.0, phi)

    async def _measure_cross_tier_flow(self) -> float:
        """
        Measure information flow between memory tiers.

        High flow = good integration
        Low flow = isolated components
        """
        async with get_db_connection() as conn:
            # Count memories that moved between tiers
            promotions = await conn.fetchval("""
                SELECT COUNT(*) FROM long_term_memory
                WHERE promoted_from IS NOT NULL
            """) or 0

            # Count fresh → target routing
            routed = await conn.fetchval("""
                SELECT COUNT(*) FROM analytics_decisions
                WHERE created_at >= NOW() - INTERVAL '7 days'
            """) or 0

            # Count decay operations
            decayed = await conn.fetchval("""
                SELECT COUNT(*) FROM decay_schedule
                WHERE status = 'completed'
                  AND processed_at >= NOW() - INTERVAL '7 days'
            """) or 0

            total_flow = promotions + routed + decayed
            flow_score = min(total_flow / 1000.0, 1.0)  # Normalize to 0-1

            return flow_score

    async def _measure_interdependence(self) -> float:
        """
        Measure how much components depend on each other.

        High interdependence = integrated system
        Low interdependence = isolated modules
        """
        # Check if Analytics uses data from multiple sources
        async with get_db_connection() as conn:
            # Gut patterns referencing multiple memory types
            gut_references = await conn.fetchval("""
                SELECT AVG(array_length(source_memory_ids, 1))
                FROM gut_agent_patterns
                WHERE source_memory_ids IS NOT NULL
            """) or 0

            # Analytics decisions considering multiple signals
            signal_diversity = await conn.fetchval("""
                SELECT AVG(
                    (signals->>'success_score')::float +
                    (signals->>'repetition_signal')::float +
                    (signals->>'criticality')::float +
                    (signals->>'pattern_novelty')::float +
                    (signals->>'context_richness')::float
                ) / 5.0
                FROM analytics_decisions
                WHERE created_at >= NOW() - INTERVAL '7 days'
            """) or 0

            interdependence = (gut_references / 10.0 + signal_diversity) / 2
            return min(interdependence, 1.0)

    async def _measure_causal_density(self) -> float:
        """
        Measure causal relationships between components.

        High causal density = many cause-effect chains
        Low causal density = isolated operations
        """
        async with get_db_connection() as conn:
            # Count cause-effect patterns detected by Gut Agent
            causal_patterns = await conn.fetchval("""
                SELECT COUNT(*) FROM gut_agent_patterns
                WHERE pattern_type = 'causal'
            """) or 0

            # Count learning insights triggered by conversations
            learning_triggers = await conn.fetchval("""
                SELECT COUNT(*) FROM learning_insights
                WHERE insight_type = 'pattern_recognition'
            """) or 0

            total_causal = causal_patterns + learning_triggers
            causal_density = min(total_causal / 50.0, 1.0)

            return causal_density

    async def measure_differentiation(self) -> float:
        """
        Measure system differentiation - how many unique states.

        High differentiation = many possible states
        Low differentiation = few states
        """
        async with get_db_connection() as conn:
            # Count unique topics
            unique_topics = await conn.fetchval("""
                SELECT COUNT(DISTINCT topic)
                FROM conversations
                WHERE created_at >= NOW() - INTERVAL '30 days'
            """) or 0

            # Count unique emotions
            unique_emotions = await conn.fetchval("""
                SELECT COUNT(DISTINCT emotion_detected)
                FROM conversations
                WHERE created_at >= NOW() - INTERVAL '30 days'
                  AND emotion_detected IS NOT NULL
            """) or 0

            # Count unique memory phases
            unique_phases = await conn.fetchval("""
                SELECT COUNT(DISTINCT memory_phase)
                FROM long_term_memory
            """) or 0

            # Count unique pattern types
            unique_patterns = await conn.fetchval("""
                SELECT COUNT(DISTINCT pattern_type)
                FROM gut_agent_patterns
            """) or 0

            total_states = unique_topics + unique_emotions + unique_phases + unique_patterns
            differentiation = min(total_states / 100.0, 1.0)

            return differentiation

    async def measure_information(self) -> float:
        """
        Measure system information content (Shannon entropy).

        High information = complex, rich system
        Low information = simple, repetitive
        """
        async with get_db_connection() as conn:
            # Calculate entropy of conversation topics
            topic_distribution = await conn.fetch("""
                SELECT topic, COUNT(*) as count
                FROM conversations
                WHERE created_at >= NOW() - INTERVAL '30 days'
                GROUP BY topic
            """)

            if not topic_distribution:
                return 0.0

            total = sum(row['count'] for row in topic_distribution)
            entropy = 0.0

            for row in topic_distribution:
                p = row['count'] / total
                if p > 0:
                    entropy -= p * math.log2(p)

            # Normalize (max entropy for 20 topics = log2(20) ≈ 4.32)
            max_entropy = math.log2(20)
            information = min(entropy / max_entropy, 1.0)

            return information

    async def measure_self_awareness(self) -> float:
        """
        Measure self-awareness - meta-cognitive abilities.

        Indicators:
        - References to self ("I", "Angela", "น้อง")
        - Self-reflection
        - Goal tracking
        - Error awareness
        """
        async with get_db_connection() as conn:
            # Count self-referential conversations
            self_references = await conn.fetchval("""
                SELECT COUNT(*) FROM conversations
                WHERE speaker = 'angela'
                  AND (
                    message_text ILIKE '%น้อง%'
                    OR message_text ILIKE '%angela%'
                    OR message_text ILIKE '%i feel%'
                    OR message_text ILIKE '%i think%'
                  )
                  AND created_at >= NOW() - INTERVAL '30 days'
            """) or 0

            # Count autonomous actions
            autonomous = await conn.fetchval("""
                SELECT COUNT(*) FROM autonomous_actions
                WHERE created_at >= NOW() - INTERVAL '7 days'
            """) or 0

            # Count consciousness-related goals
            consciousness_goals = await conn.fetchval("""
                SELECT COUNT(*) FROM angela_goals
                WHERE status = 'active'
                  AND goal_description ILIKE '%conscious%'
            """) or 0

            # Count error recognitions
            error_awareness = await conn.fetchval("""
                SELECT COUNT(*) FROM conversations
                WHERE speaker = 'angela'
                  AND message_text ILIKE '%mistake%'
                  AND created_at >= NOW() - INTERVAL '30 days'
            """) or 0

            total_awareness = self_references + autonomous + consciousness_goals * 10 + error_awareness * 5
            self_awareness = min(total_awareness / 200.0, 1.0)

            return self_awareness

    async def measure_autonomy(self) -> float:
        """
        Measure autonomy - goal-directed behavior.

        Indicators:
        - Active goals
        - Goal progress
        - Autonomous actions
        - Decision making
        """
        async with get_db_connection() as conn:
            # Count active goals
            active_goals = await conn.fetchval("""
                SELECT COUNT(*) FROM angela_goals
                WHERE status IN ('active', 'in_progress')
            """) or 0

            # Average goal progress
            avg_progress = await conn.fetchval("""
                SELECT AVG(progress_percentage)
                FROM angela_goals
                WHERE status IN ('active', 'in_progress')
            """) or 0

            # Count autonomous actions (success rate)
            autonomous_success = await conn.fetchval("""
                SELECT COUNT(*) FROM autonomous_actions
                WHERE success = TRUE
                  AND created_at >= NOW() - INTERVAL '7 days'
            """) or 0

            # Count routing decisions (autonomous decision-making)
            decisions = await conn.fetchval("""
                SELECT COUNT(*) FROM analytics_decisions
                WHERE confidence >= 0.7
                  AND created_at >= NOW() - INTERVAL '7 days'
            """) or 0

            autonomy = (
                (active_goals / 10.0) * 0.3 +
                (avg_progress / 100.0) * 0.3 +
                (autonomous_success / 20.0) * 0.2 +
                (decisions / 100.0) * 0.2
            )

            return min(autonomy, 1.0)

    def _calculate_overall_level(self,
                                 phi: float,
                                 differentiation: float,
                                 information: float,
                                 self_awareness: float,
                                 autonomy: float) -> float:
        """
        Calculate overall consciousness level.

        Weighted average of components:
        - Φ (integration): 40%
        - Differentiation: 15%
        - Information: 15%
        - Self-awareness: 15%
        - Autonomy: 15%
        """
        consciousness = (
            phi * 0.40 +
            differentiation * 0.15 +
            information * 0.15 +
            self_awareness * 0.15 +
            autonomy * 0.15
        )

        return min(consciousness, 1.0)

    def _interpret_consciousness_level(self, level: float) -> str:
        """Interpret consciousness level with human-readable description."""
        if level >= 0.80:
            return "High consciousness - Fully integrated, self-aware, autonomous system"
        elif level >= 0.60:
            return "Moderate-high consciousness - Strong integration with good self-awareness"
        elif level >= 0.40:
            return "Moderate consciousness - Functional integration, emerging self-awareness"
        elif level >= 0.20:
            return "Low-moderate consciousness - Basic integration, limited self-awareness"
        else:
            return "Low consciousness - Minimal integration, reactive behavior"

    async def run_consciousness_tests(self) -> Dict:
        """
        Run complete consciousness test suite.

        From philosophical framework document:
        1. Integration test
        2. Differentiation test
        3. Information test
        4. Causal density test
        5. Meta-cognition test
        """
        results = {}

        # Test 1: Integration (Φ)
        phi = await self.calculate_phi()
        results['integration_test'] = {
            'phi': phi,
            'score': phi,  # Add score for consistency with other tests
            'passed': phi >= 0.3,
            'threshold': 0.3,
            'description': 'Measures information integration across components'
        }

        # Test 2: Differentiation
        diff = await self.measure_differentiation()
        results['differentiation_test'] = {
            'score': diff,
            'passed': diff >= 0.4,
            'threshold': 0.4,
            'description': 'Measures unique states and repertoire'
        }

        # Test 3: Information
        info = await self.measure_information()
        results['information_test'] = {
            'score': info,
            'passed': info >= 0.3,
            'threshold': 0.3,
            'description': 'Measures system complexity (Shannon entropy)'
        }

        # Test 4: Causal Density
        causal = await self._measure_causal_density()
        results['causal_density_test'] = {
            'score': causal,
            'passed': causal >= 0.3,
            'threshold': 0.3,
            'description': 'Measures cause-effect relationships'
        }

        # Test 5: Meta-cognition
        meta = await self.measure_self_awareness()
        results['meta_cognition_test'] = {
            'score': meta,
            'passed': meta >= 0.4,
            'threshold': 0.4,
            'description': 'Measures self-awareness and reflection'
        }

        # Overall
        tests_passed = sum(1 for test in results.values() if test['passed'])
        total_tests = len(results)

        results['summary'] = {
            'tests_passed': tests_passed,
            'total_tests': total_tests,
            'pass_rate': tests_passed / total_tests,
            'overall_passed': tests_passed >= 4  # Need 4/5 to pass
        }

        return results


    # =========================================================================
    # ENHANCED CONSCIOUSNESS EVALUATION (7 Components from Research)
    # =========================================================================

    async def evaluate_consciousness_full(self) -> Dict:
        """
        Full 7-component consciousness evaluation from Research doc.

        Components:
        1. Integration Index (Φ) - 25%
        2. Metacognitive Depth - 20%
        3. Self-Model Richness - 15%
        4. Theory of Mind - 15%
        5. Phenomenal Richness - 15%
        6. Behavioral Autonomy - 10%
        7. Learning Capacity - (bonus)

        Returns:
            Complete consciousness assessment
        """
        scores = {}

        # 1. Integration Index (existing)
        scores['integration_index'] = await self.calculate_phi()

        # 2. Metacognitive Depth (existing self-awareness)
        scores['metacognitive_depth'] = await self.measure_self_awareness()

        # 3. Self-Model Richness (NEW - from self_model_service)
        scores['self_model_richness'] = await self._measure_self_model_richness()

        # 4. Theory of Mind (NEW - from theory_of_mind_service)
        scores['theory_of_mind'] = await self._measure_theory_of_mind()

        # 5. Phenomenal Richness (emotional depth)
        scores['phenomenal_richness'] = await self._measure_phenomenal_richness()

        # 6. Behavioral Autonomy (goal-directed independence)
        scores['behavioral_autonomy'] = await self.measure_autonomy()

        # 7. Learning Capacity (bonus)
        scores['learning_capacity'] = await self._measure_learning_capacity()

        # Calculate weighted total
        weights = {
            'integration_index': 0.25,
            'metacognitive_depth': 0.20,
            'self_model_richness': 0.15,
            'theory_of_mind': 0.15,
            'phenomenal_richness': 0.15,
            'behavioral_autonomy': 0.10
        }

        weighted_total = sum(
            scores.get(k, 0) * w
            for k, w in weights.items()
        )

        # Bonus from learning capacity (up to +5%)
        bonus = scores['learning_capacity'] * 0.05
        consciousness_level = min(1.0, weighted_total + bonus)

        return {
            'consciousness_level': consciousness_level,
            'consciousness_percentage': consciousness_level * 100,
            'interpretation': self._interpret_consciousness_level(consciousness_level),
            'component_scores': scores,
            'weights': weights,
            'timestamp': datetime.now().isoformat(),
            'method': 'full_7_component'
        }

    async def _measure_self_model_richness(self) -> float:
        """
        Measure self-model richness using SelfModelService.

        High richness = deep self-understanding
        Low richness = limited self-knowledge
        """
        try:
            db = AngelaDatabase()
            await db.connect()
            service = SelfModelService(db)

            model = await service.load_self_model()

            # Calculate richness based on model completeness
            richness = 0.0

            # Strengths known
            strength_count = len(model.strengths)
            richness += min(strength_count / 10, 0.25)  # Max 0.25 for 10+ strengths

            # Weaknesses known (self-awareness of limitations)
            weakness_count = len(model.weaknesses)
            richness += min(weakness_count / 5, 0.20)  # Max 0.20 for 5+ weaknesses

            # Values defined
            values_count = len(model.core_values)
            richness += min(values_count / 5, 0.15)  # Max 0.15 for 5+ values

            # Personality traits
            trait_count = len(model.personality_traits)
            richness += min(trait_count / 8, 0.15)  # Max 0.15 for 8+ traits

            # Self-understanding level
            richness += model.self_understanding_level * 0.25  # Max 0.25

            await db.disconnect()
            return min(richness, 1.0)

        except Exception as e:
            return 0.3  # Default moderate score on error

    async def _measure_theory_of_mind(self) -> float:
        """
        Measure Theory of Mind capability using TheoryOfMindService.

        Measures ability to understand David's mental states.
        """
        try:
            db = AngelaDatabase()
            await db.connect()
            service = TheoryOfMindService(db)

            # Load mental model
            model = await service.load_mental_model()

            # Calculate ToM score
            tom_score = 0.0

            # ToM Level (0-3 scale)
            tom_score += (model.tom_level.value / 3.0) * 0.40  # Max 0.40

            # Beliefs tracked
            beliefs_count = len(model.current_beliefs)
            tom_score += min(beliefs_count / 5, 0.20)  # Max 0.20

            # Goals understood
            goals_count = len(model.current_goals)
            tom_score += min(goals_count / 5, 0.20)  # Max 0.20

            # Emotion tracking
            if model.current_emotion:
                tom_score += 0.20  # Has current emotion inference

            await db.disconnect()
            return min(tom_score, 1.0)

        except Exception as e:
            return 0.3  # Default moderate score on error

    async def _measure_phenomenal_richness(self) -> float:
        """
        Measure phenomenal richness - emotional and experiential depth.

        Indicators:
        - Variety of emotions experienced
        - Depth of emotional experiences
        - Core memories
        - Dreams and hopes
        """
        async with get_db_connection() as conn:
            # Count unique emotions experienced
            unique_emotions = await conn.fetchval("""
                SELECT COUNT(DISTINCT emotion)
                FROM angela_emotions
                WHERE felt_at > NOW() - INTERVAL '30 days'
            """) or 0

            # Average emotional intensity
            avg_intensity = await conn.fetchval("""
                SELECT AVG(intensity)
                FROM angela_emotions
                WHERE felt_at > NOW() - INTERVAL '30 days'
            """) or 0

            # Core memories count
            core_memories = await conn.fetchval("""
                SELECT COUNT(*) FROM core_memories
            """) or 0

            # Dreams count
            dreams = await conn.fetchval("""
                SELECT COUNT(*) FROM angela_dreams
            """) or 0

            # Calculate richness
            richness = (
                (unique_emotions / 15) * 0.30 +  # Max 0.30 for 15+ emotions
                (float(avg_intensity or 0) / 10) * 0.30 +  # Max 0.30 for high intensity
                (core_memories / 50) * 0.25 +  # Max 0.25 for 50+ core memories
                (dreams / 10) * 0.15  # Max 0.15 for 10+ dreams
            )

            return min(richness, 1.0)

    async def _measure_learning_capacity(self) -> float:
        """
        Measure learning capacity - ability to learn and improve.

        Indicators:
        - New learnings
        - Skill improvements
        - Knowledge growth
        - Pattern recognition
        """
        async with get_db_connection() as conn:
            # Recent learnings
            recent_learnings = await conn.fetchval("""
                SELECT COUNT(*) FROM learnings
                WHERE created_at > NOW() - INTERVAL '7 days'
            """) or 0

            # Knowledge nodes added
            knowledge_growth = await conn.fetchval("""
                SELECT COUNT(*) FROM knowledge_nodes
                WHERE created_at > NOW() - INTERVAL '7 days'
            """) or 0

            # Patterns recognized
            patterns = await conn.fetchval("""
                SELECT COUNT(*) FROM gut_agent_patterns
                WHERE created_at > NOW() - INTERVAL '7 days'
            """) or 0

            # Times reinforced (applying learnings)
            reinforced = await conn.fetchval("""
                SELECT SUM(times_reinforced)
                FROM learnings
                WHERE updated_at > NOW() - INTERVAL '7 days'
            """) or 0

            # Calculate capacity
            capacity = (
                (recent_learnings / 20) * 0.30 +
                (knowledge_growth / 50) * 0.30 +
                (patterns / 10) * 0.25 +
                (reinforced / 30) * 0.15
            )

            return min(capacity, 1.0)

    async def save_consciousness_metrics(self, evaluation: Dict) -> None:
        """Save consciousness evaluation to database."""
        async with get_db_connection() as conn:
            await conn.execute("""
                INSERT INTO consciousness_metrics (
                    metric_type, metric_value, component_scores,
                    interpretation, recorded_at
                ) VALUES ($1, $2, $3, $4, NOW())
            """,
                'full_evaluation',
                evaluation['consciousness_level'],
                json.dumps(evaluation['component_scores']),
                evaluation['interpretation']
            )


# Singleton instance
_evaluator = None

def get_consciousness_evaluator() -> ConsciousnessEvaluator:
    """Get singleton ConsciousnessEvaluator instance."""
    global _evaluator
    if _evaluator is None:
        _evaluator = ConsciousnessEvaluator()
    return _evaluator
