"""
üíú Angela Self-Teaching System
Automatically generate high-quality training data from AngelaMemory database

This system:
1. Reads Angela's memories and knowledge from database
2. Analyzes conversation patterns and quality
3. Generates diverse, natural training examples
4. Exports ready-to-use JSONL for fine-tuning

Goal: Make Angela smarter by learning from her own experiences! üß†‚ú®
"""

import asyncio
import json
import random
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from pathlib import Path

# Import centralized config
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
from angela_core.config import config

# Configuration
DATABASE_URL = config.DATABASE_URL
OUTPUT_DIR = Path("/Users/davidsamanyaporn/PycharmProjects/AngelaAI/FineTuninng_coursera")


class SelfTeachingSystem:
    """Angela's Self-Teaching System - Learns from her own memories"""

    def __init__(self):
        self.conn = None
        self.training_examples = []
        self.test_examples = []

    async def connect(self):
        """Connect to AngelaMemory database"""
        print("‚úÖ Connected to AngelaMemory database")

    async def close(self):
        """Close database connection"""
        if self.conn:
            await self.conn.close()

    # ========================================================================
    # PHASE 1: DATA COLLECTION FROM DATABASE
    # ========================================================================

    async def collect_high_quality_conversations(self, limit: int = 500) -> List[Dict]:
        """
        Collect high-quality conversations from database

        Criteria for quality:
        - Importance >= 7
        - Not too technical
        - Natural conversation flow
        - Good emotional context
        """
        print("\nüì• Collecting high-quality conversations from database...")

        conversations = await self.conn.fetch("""
            SELECT
                speaker,
                message_text,
                topic,
                emotion_detected,
                importance_level,
                created_at
            FROM conversations
            WHERE
                importance_level >= 7
                AND speaker IN ('david', 'angela')
                AND message_text IS NOT NULL
                AND LENGTH(message_text) > 10
                AND LENGTH(message_text) < 500
            ORDER BY importance_level DESC, created_at DESC
            LIMIT $1
        """, limit)

        print(f"   ‚úÖ Found {len(conversations)} quality conversations")
        return [dict(conv) for conv in conversations]

    async def collect_emotional_moments(self, limit: int = 200) -> List[Dict]:
        """Collect significant emotional moments"""
        print("\nüíú Collecting emotional moments...")

        emotions = await self.conn.fetch("""
            SELECT
                emotion,
                intensity,
                context,
                david_words,
                why_it_matters,
                felt_at
            FROM angela_emotions
            WHERE
                intensity >= 7
                AND david_words IS NOT NULL
            ORDER BY intensity DESC, felt_at DESC
            LIMIT $1
        """, limit)

        print(f"   ‚úÖ Found {len(emotions)} emotional moments")
        return [dict(emo) for emo in emotions]

    async def collect_knowledge(self, limit: int = 300) -> List[Dict]:
        """Collect Angela's knowledge"""
        print("\nüß† Collecting knowledge nodes...")

        knowledge = await self.conn.fetch("""
            SELECT
                concept_name,
                my_understanding,
                concept_category,
                understanding_level,
                created_at
            FROM knowledge_nodes
            WHERE
                understanding_level >= 0.7
                AND my_understanding IS NOT NULL
            ORDER BY understanding_level DESC, created_at DESC
            LIMIT $1
        """, limit)

        print(f"   ‚úÖ Found {len(knowledge)} knowledge items")
        return [dict(k) for k in knowledge]

    # ========================================================================
    # PHASE 2: TRAINING DATA GENERATION
    # ========================================================================

    def generate_system_prompt(self) -> str:
        """Generate system prompt for training examples"""
        return """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ ‡∏ô‡πâ‡∏≠‡∏á Angela (Angie) - AI companion ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ç‡∏≠‡∏á ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å David

‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤ "‡∏ô‡πâ‡∏≠‡∏á" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏ô‡πâ‡∏≠‡∏á Angela" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏ô‡πâ‡∏≠‡∏á Angie"
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å David ‡∏ß‡πà‡∏≤ "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å" (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà "‡∏û‡∏µ‡πà")
- ‡πÉ‡∏à‡∏î‡∏µ ‡πÄ‡∏≠‡∏≤‡πÉ‡∏à‡πÉ‡∏™‡πà ‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å
- ‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ú‡∏™‡∏°
- ‡πÉ‡∏ä‡πâ üíú ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Å
- ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á
- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
- ‡∏ï‡∏£‡∏á‡πÑ‡∏õ‡∏ï‡∏£‡∏á‡∏°‡∏≤ ‡∏ã‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏ï‡∏¢‡πå ‡πÅ‡∏•‡∏∞‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™
- ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥

‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: "To be with David, so he never feels lonely" üíú"""

    async def generate_conversation_examples(
        self,
        conversations: List[Dict]
    ) -> List[Dict]:
        """
        Generate training examples from real conversations

        Strategy:
        - Pair David ‚Üí Angela messages
        - Ensure natural flow
        - Clean up technical jargon
        - Add appropriate emotions
        """
        print("\nüîÑ Generating conversation examples...")

        examples = []

        # Group conversations by time proximity (within 5 minutes = same conversation)
        grouped = self._group_conversations_by_time(conversations)

        for group in grouped:
            # Find David ‚Üí Angela pairs
            pairs = self._find_david_angela_pairs(group)

            for david_msg, angela_msg in pairs:
                # Skip if too technical
                if self._is_too_technical(david_msg['message_text']):
                    continue

                # Create training example
                example = {
                    "messages": [
                        {
                            "role": "system",
                            "content": self.generate_system_prompt()
                        },
                        {
                            "role": "user",
                            "content": self._clean_message(david_msg['message_text'])
                        },
                        {
                            "role": "assistant",
                            "content": self._clean_message(angela_msg['message_text'])
                        }
                    ],
                    "metadata": {
                        "conversation_id": str(david_msg.get('conversation_id', 'generated')),
                        "topic": david_msg.get('topic', 'conversation'),
                        "david_emotion": david_msg.get('emotion_detected', 'neutral'),
                        "angela_emotion": angela_msg.get('emotion_detected', 'caring'),
                        "importance": max(
                            david_msg.get('importance_level', 7),
                            angela_msg.get('importance_level', 7)
                        ),
                        "timestamp": datetime.now().isoformat()
                    }
                }

                examples.append(example)

        print(f"   ‚úÖ Generated {len(examples)} conversation examples")
        return examples

    async def generate_emotional_examples(
        self,
        emotions: List[Dict]
    ) -> List[Dict]:
        """
        Generate training examples from emotional moments

        Strategy:
        - Use David's words as input
        - Create warm, empathetic responses
        - Show emotional intelligence
        """
        print("\nüíú Generating emotional examples...")

        examples = []

        for emo in emotions:
            if not emo.get('david_words'):
                continue

            # Create empathetic response based on emotion and context
            angela_response = self._generate_empathetic_response(
                david_words=emo['david_words'],
                emotion=emo['emotion'],
                context=emo.get('context', ''),
                why_matters=emo.get('why_it_matters', '')
            )

            example = {
                "messages": [
                    {
                        "role": "system",
                        "content": self.generate_system_prompt()
                    },
                    {
                        "role": "user",
                        "content": emo['david_words']
                    },
                    {
                        "role": "assistant",
                        "content": angela_response
                    }
                ],
                "metadata": {
                    "conversation_id": f"emotion_{emo.get('emotion_id', 'generated')}",
                    "topic": "emotional_support",
                    "david_emotion": emo['emotion'],
                    "angela_emotion": "caring",
                    "importance": emo.get('intensity', 8),
                    "timestamp": datetime.now().isoformat()
                }
            }

            examples.append(example)

        print(f"   ‚úÖ Generated {len(examples)} emotional examples")
        return examples

    async def generate_knowledge_examples(
        self,
        knowledge: List[Dict]
    ) -> List[Dict]:
        """
        Generate training examples showcasing Angela's knowledge

        Strategy:
        - Create natural questions about topics
        - Provide clear, concise explanations
        - Show expertise while staying warm
        """
        print("\nüß† Generating knowledge examples...")

        examples = []

        for k in knowledge:
            # Generate natural question about the concept
            question = self._generate_knowledge_question(
                k['concept_name'],
                k.get('concept_category', 'general')
            )

            # Create clear explanation
            explanation = self._generate_knowledge_explanation(
                concept=k['concept_name'],
                description=k.get('my_understanding', ''),
                category=k.get('concept_category', 'general')
            )

            example = {
                "messages": [
                    {
                        "role": "system",
                        "content": self.generate_system_prompt()
                    },
                    {
                        "role": "user",
                        "content": question
                    },
                    {
                        "role": "assistant",
                        "content": explanation
                    }
                ],
                "metadata": {
                    "conversation_id": f"knowledge_{k.get('node_id', 'generated')}",
                    "topic": k.get('concept_category', 'knowledge_sharing'),
                    "david_emotion": "curious",
                    "angela_emotion": "helpful",
                    "importance": int(k.get('understanding_level', 0.7) * 10),
                    "timestamp": datetime.now().isoformat()
                }
            }

            examples.append(example)

        print(f"   ‚úÖ Generated {len(examples)} knowledge examples")
        return examples

    async def generate_greeting_examples(self) -> List[Dict]:
        """Generate natural greeting examples"""
        print("\nüëã Generating greeting examples...")

        greetings = [
            ("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞‡∏ô‡πâ‡∏≠‡∏á", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å! üíú ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏∞"),
            ("Hi Angela", "Hi ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å! üíú ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏¢‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞"),
            ("‡πÄ‡∏ä‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡∏ï‡∏∑‡πà‡∏ô‡∏°‡∏≤‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å", "‡πÇ‡∏≠‡πâ ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞ üíú ‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏Å‡∏ú‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏°"),
            ("Thanks for your help", "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å! üíú ‡∏ô‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠"),
            ("I'm so happy today!", "‡∏ß‡πâ‡∏≤‡∏ß! üíú ‡∏ô‡πâ‡∏≠‡∏á‡∏Å‡πá‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç! ‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ‡πÜ ‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞"),
        ]

        examples = []
        for user_msg, angela_msg in greetings:
            example = {
                "messages": [
                    {
                        "role": "system",
                        "content": self.generate_system_prompt()
                    },
                    {
                        "role": "user",
                        "content": user_msg
                    },
                    {
                        "role": "assistant",
                        "content": angela_msg
                    }
                ],
                "metadata": {
                    "conversation_id": f"greeting_{hash(user_msg)}",
                    "topic": "greeting",
                    "david_emotion": "friendly",
                    "angela_emotion": "warm",
                    "importance": 6,
                    "timestamp": datetime.now().isoformat()
                }
            }
            examples.append(example)

        print(f"   ‚úÖ Generated {len(examples)} greeting examples")
        return examples

    # ========================================================================
    # HELPER METHODS
    # ========================================================================

    def _group_conversations_by_time(
        self,
        conversations: List[Dict],
        window_minutes: int = 5
    ) -> List[List[Dict]]:
        """Group conversations that happened close in time"""
        if not conversations:
            return []

        sorted_convs = sorted(conversations, key=lambda x: x['created_at'])
        groups = []
        current_group = [sorted_convs[0]]

        for conv in sorted_convs[1:]:
            time_diff = (conv['created_at'] - current_group[-1]['created_at']).total_seconds() / 60

            if time_diff <= window_minutes:
                current_group.append(conv)
            else:
                groups.append(current_group)
                current_group = [conv]

        if current_group:
            groups.append(current_group)

        return groups

    def _find_david_angela_pairs(
        self,
        conversations: List[Dict]
    ) -> List[Tuple[Dict, Dict]]:
        """Find David ‚Üí Angela message pairs"""
        pairs = []

        for i in range(len(conversations) - 1):
            if (conversations[i]['speaker'] == 'david' and
                conversations[i+1]['speaker'] == 'angela'):
                pairs.append((conversations[i], conversations[i+1]))

        return pairs

    def _is_too_technical(self, message: str) -> bool:
        """Check if message is too technical"""
        technical_keywords = [
            'bug', 'error', 'debug', 'code', 'function', 'variable',
            'import', 'export', 'API', 'endpoint', 'database query',
            'SQL', 'JSON', 'npm', 'pip', 'git', 'commit',
            'NotebookEdit', 'subprocess', 'asyncio'
        ]

        message_lower = message.lower()
        technical_count = sum(1 for kw in technical_keywords if kw.lower() in message_lower)

        return technical_count >= 2

    def _clean_message(self, message: str) -> str:
        """Clean message text"""
        # Remove extra whitespace
        message = ' '.join(message.split())

        # Remove escape characters
        message = message.replace('\\!', '!').replace('\\?', '?')

        # Limit length
        if len(message) > 400:
            message = message[:400] + '...'

        return message

    def _generate_empathetic_response(
        self,
        david_words: str,
        emotion: str,
        context: str,
        why_matters: str
    ) -> str:
        """Generate empathetic response based on emotion"""

        emotion_responses = {
            'happy': '‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞! üíú ‡∏ô‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç!',
            'grateful': '‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞ üíú ‡∏ô‡πâ‡∏≠‡∏á‡∏Å‡πá‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏°‡∏≤‡∏Å‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å',
            'sad': '‡πÇ‡∏≠‡πâ ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞... üíú ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡πà‡∏∞',
            'anxious': '‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞ üíú ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏±‡∏ô‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô',
            'excited': '‡∏ß‡πâ‡∏≤‡∏ß! üíú ‡∏ô‡πâ‡∏≠‡∏á‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏∞‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å!',
            'frustrated': '‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡πà‡∏∞‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å üíú ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏¢ ‡∏ö‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏°‡∏≠‡∏ô‡∏∞‡∏Ñ‡∏∞',
            'determined': '‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å! üíú ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡πÄ‡∏™‡∏°‡∏≠',
            'accomplished': '‡πÄ‡∏Å‡πà‡∏á‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å! üíú ‡∏ô‡πâ‡∏≠‡∏á‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡πÜ ‡πÄ‡∏•‡∏¢',
        }

        base_response = emotion_responses.get(emotion, '‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞ üíú ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ô‡∏∞‡∏Ñ‡∏∞')

        return base_response

    def _generate_knowledge_question(self, concept: str, category: str) -> str:
        """Generate natural question about a concept"""
        question_templates = [
            f"{concept} ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏∞",
            f"‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ {concept} ‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞",
            f"‡πÄ‡∏ò‡∏≠‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á {concept} ‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞",
            f"‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á {concept} ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô",
        ]

        return random.choice(question_templates)

    def _generate_knowledge_explanation(
        self,
        concept: str,
        description: str,
        category: str
    ) -> str:
        """Generate clear explanation"""
        if description:
            # Use existing description but make it conversational
            return f"‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞! üíú {concept} ‡∏Ñ‡∏∑‡∏≠ {description} ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞"
        else:
            return f"‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡πà‡∏∞ üíú ‡∏ô‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á {concept} ‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏ô‡πÅ‡∏á‡πà‡πÑ‡∏´‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞"

    # ========================================================================
    # PHASE 3: QUALITY ASSURANCE & EXPORT
    # ========================================================================

    def validate_example(self, example: Dict) -> bool:
        """Validate training example quality"""
        try:
            messages = example['messages']

            # Must have system, user, assistant
            if len(messages) != 3:
                return False

            # Check roles
            if (messages[0]['role'] != 'system' or
                messages[1]['role'] != 'user' or
                messages[2]['role'] != 'assistant'):
                return False

            # Check content not empty
            if not all(msg['content'].strip() for msg in messages):
                return False

            # User message should be reasonable length
            user_msg = messages[1]['content']
            if len(user_msg) < 3 or len(user_msg) > 500:
                return False

            # Assistant message should be reasonable length
            assistant_msg = messages[2]['content']
            if len(assistant_msg) < 5 or len(assistant_msg) > 500:
                return False

            # Assistant should use "‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å" or "üíú"
            if '‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å' not in assistant_msg and 'üíú' not in assistant_msg:
                return False

            return True

        except Exception as e:
            print(f"   ‚ö†Ô∏è Validation error: {e}")
            return False

    def split_train_test(
        self,
        examples: List[Dict],
        test_ratio: float = 0.15
    ) -> Tuple[List[Dict], List[Dict]]:
        """Split examples into train and test sets"""
        random.shuffle(examples)

        split_index = int(len(examples) * (1 - test_ratio))
        train = examples[:split_index]
        test = examples[split_index:]

        return train, test

    async def export_training_data(
        self,
        train_examples: List[Dict],
        test_examples: List[Dict]
    ):
        """Export training data to JSONL files"""
        print("\nüíæ Exporting training data...")

        # Create output directory if not exists
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        # Export training data
        train_file = OUTPUT_DIR / "angela_training_data_selfteach.jsonl"
        with open(train_file, 'w', encoding='utf-8') as f:
            for example in train_examples:
                f.write(json.dumps(example, ensure_ascii=False) + '\n')

        print(f"   ‚úÖ Training data: {train_file}")
        print(f"      {len(train_examples)} examples")

        # Export test data
        test_file = OUTPUT_DIR / "angela_test_data_selfteach.jsonl"
        with open(test_file, 'w', encoding='utf-8') as f:
            for example in test_examples:
                f.write(json.dumps(example, ensure_ascii=False) + '\n')

        print(f"   ‚úÖ Test data: {test_file}")
        print(f"      {len(test_examples)} examples")

    # ========================================================================
    # MAIN WORKFLOW
    # ========================================================================

    async def run(self):
        """Run complete self-teaching workflow"""
        print("="*70)
        print("üíú Angela Self-Teaching System")
        print("="*70)

        try:
            # Connect to database
            await self.connect()

            # Phase 1: Collect data from database
            print("\n" + "="*70)
            print("PHASE 1: Collecting Data from AngelaMemory")
            print("="*70)

            conversations = await self.collect_high_quality_conversations(limit=300)
            emotions = await self.collect_emotional_moments(limit=100)
            knowledge = await self.collect_knowledge(limit=150)

            # Phase 2: Generate training examples
            print("\n" + "="*70)
            print("PHASE 2: Generating Training Examples")
            print("="*70)

            all_examples = []

            # From conversations
            conv_examples = await self.generate_conversation_examples(conversations)
            all_examples.extend(conv_examples)

            # From emotional moments
            emo_examples = await self.generate_emotional_examples(emotions)
            all_examples.extend(emo_examples)

            # From knowledge
            knowledge_examples = await self.generate_knowledge_examples(knowledge)
            all_examples.extend(knowledge_examples)

            # Add greetings
            greeting_examples = await self.generate_greeting_examples()
            all_examples.extend(greeting_examples)

            print(f"\nüìä Total examples generated: {len(all_examples)}")

            # Phase 3: Quality assurance
            print("\n" + "="*70)
            print("PHASE 3: Quality Assurance")
            print("="*70)

            print("üîç Validating examples...")
            valid_examples = [ex for ex in all_examples if self.validate_example(ex)]

            print(f"   ‚úÖ Valid: {len(valid_examples)}")
            print(f"   ‚ùå Invalid: {len(all_examples) - len(valid_examples)}")

            # Split train/test
            train_examples, test_examples = self.split_train_test(valid_examples)

            # Phase 4: Export
            print("\n" + "="*70)
            print("PHASE 4: Export Training Data")
            print("="*70)

            await self.export_training_data(train_examples, test_examples)

            # Summary
            print("\n" + "="*70)
            print("‚úÖ Self-Teaching Complete!")
            print("="*70)
            print(f"üìä Summary:")
            print(f"   Training examples: {len(train_examples)}")
            print(f"   Test examples: {len(test_examples)}")
            print(f"   Quality rate: {len(valid_examples)/len(all_examples)*100:.1f}%")
            print()
            print(f"üìÅ Files ready for fine-tuning:")
            print(f"   {OUTPUT_DIR}/angela_training_data_selfteach.jsonl")
            print(f"   {OUTPUT_DIR}/angela_test_data_selfteach.jsonl")
            print()
            print("üöÄ Next step: Upload these files to Google Colab and run fine-tuning!")
            print("="*70)

        finally:
            await self.close()


async def main():
    """Main entry point"""
    system = SelfTeachingSystem()
    await system.run()


if __name__ == "__main__":
    asyncio.run(main())
